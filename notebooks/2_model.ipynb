{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94367b78",
   "metadata": {},
   "source": [
    "# Data Exploration: Elliptic Dataset\n",
    "# Augmentate network features\n",
    "https://www.kaggle.com/datasets/ellipticco/elliptic-data-set/data\n",
    "\n",
    "[1] Elliptic, www.elliptic.co.\n",
    "\n",
    "[2] M. Weber, G. Domeniconi, J. Chen, D. K. I. Weidele, C. Bellei, T. Robinson, C. E. Leiserson, \"Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics\", KDD â€™19 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA.\n",
    "\n",
    "Description: The Elliptic Data Set maps Bitcoin transactions to real entities belonging to licit categories (exchanges, wallet providers, miners, licit services, etc.) versus illicit ones (scams, malware, terrorist organizations, ransomware, Ponzi schemes, etc.). The task on the dataset is to classify the illicit and licit nodes in the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851d1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from src.data.load_data import load_elliptic_dataset\n",
    "from src.visualization.graphs import plot_transaction_graph\n",
    "from src.data.preprocess import corr_with_binary_labels\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0882558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3443bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/raw/'\n",
    "nodes_df, edges_df = load_elliptic_dataset(DATA_PATH)\n",
    "nodes_df['class_label'] = nodes_df['class_label'].replace(['1', '2', 'unknown'], ['illicit', 'licit', 'unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d984b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16985d4d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ddaebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, df, feature_cols = edges_df, nodes_df, nodes_df.drop(columns=['txId', 'time_step', 'class_label']).columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38ba3a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "txId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gw_hit_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gw_min_step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gw_avg_step",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gw_unique_illicit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class_label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bb12f507-bae3-450c-8383-e4d12862b146",
       "rows": [
        [
         "907",
         "232629023",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "1361",
         "230389796",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "2718",
         "17387772",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "2815",
         "232947878",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "3423",
         "16754007",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "4881",
         "231990430",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "5037",
         "232014511",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "5120",
         "24141114",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "5438",
         "62195631",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "6255",
         "24155910",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "7158",
         "16742787",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "7409",
         "231990435",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "7418",
         "17796937",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "7439",
         "184703182",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "7543",
         "16753577",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "7714",
         "232345692",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "7811",
         "3205536",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "8009",
         "115643001",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "8103",
         "310048974",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "8529",
         "310399847",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "8881",
         "286784958",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "9330",
         "289269312",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "10237",
         "258624857",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "10498",
         "309924066",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "10699",
         "286784427",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "10935",
         "289270308",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "11025",
         "312106094",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "11348",
         "312334552",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "11655",
         "212659519",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "11988",
         "286654752",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "12086",
         "313900565",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "12199",
         "296057714",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "12293",
         "310043610",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "12342",
         "286756215",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "12382",
         "310524772",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "15180",
         "244662723",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "15690",
         "245140933",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "16717",
         "245294955",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "16950",
         "245420039",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "17069",
         "245715541",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "17740",
         "27742555",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "17866",
         "245146113",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "18265",
         "246036358",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "18421",
         "245712851",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "18427",
         "245146107",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "18901",
         "245231973",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "19197",
         "86739424",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "19502",
         "87690267",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "19635",
         "45751341",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ],
        [
         "19917",
         "16809915",
         "1.0",
         "1",
         "1.0",
         "1",
         "illicit"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4545
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>gw_hit_ratio</th>\n",
       "      <th>gw_min_step</th>\n",
       "      <th>gw_avg_step</th>\n",
       "      <th>gw_unique_illicit</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>232629023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>230389796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>17387772</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>232947878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>16754007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203685</th>\n",
       "      <td>159043651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203708</th>\n",
       "      <td>158360779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203736</th>\n",
       "      <td>159028476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203759</th>\n",
       "      <td>158375075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203766</th>\n",
       "      <td>158375402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4545 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             txId  gw_hit_ratio  gw_min_step  gw_avg_step  gw_unique_illicit  \\\n",
       "907     232629023           1.0            1          1.0                  1   \n",
       "1361    230389796           1.0            1          1.0                  1   \n",
       "2718     17387772           1.0            1          1.0                  1   \n",
       "2815    232947878           1.0            1          1.0                  1   \n",
       "3423     16754007           1.0            1          1.0                  1   \n",
       "...           ...           ...          ...          ...                ...   \n",
       "203685  159043651           1.0            1          1.0                  1   \n",
       "203708  158360779           1.0            1          1.0                  1   \n",
       "203736  159028476           1.0            1          1.0                  1   \n",
       "203759  158375075           1.0            1          1.0                  1   \n",
       "203766  158375402           1.0            1          1.0                  1   \n",
       "\n",
       "       class_label  \n",
       "907        illicit  \n",
       "1361       illicit  \n",
       "2718       illicit  \n",
       "2815       illicit  \n",
       "3423       illicit  \n",
       "...            ...  \n",
       "203685     illicit  \n",
       "203708     illicit  \n",
       "203736     illicit  \n",
       "203759     illicit  \n",
       "203766     illicit  \n",
       "\n",
       "[4545 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_features.merge(nodes_df[['txId', 'class_label']], on = 'txId').query('class_label == \"illicit\" & gw_avg_step == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3093dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############################################################################\n",
    "#                 Graph Convolutional Network Embeddings                      #\n",
    "##############################################################################\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden=64, out_feats=32, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_feats, hidden)\n",
    "        self.conv2 = GCNConv(hidden, out_feats)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_gcn_get_embeddings(df, time_step_graphs, feature_cols, epochs=30, lr=1e-3, device='cpu'):\n",
    "    \"\"\"Train semi-supervised GCN for each time step and return embeddings.\"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for time_step, G in tqdm(time_step_graphs.items(), desc=\"GCN Embeddings\"):\n",
    "        if len(G.nodes()) < 10:  # Skip very small graphs\n",
    "            continue\n",
    "            \n",
    "        # Filter dataframe for nodes in this time step\n",
    "        sub_df = df[df['time_step'] == time_step]\n",
    "        nodes = list(G.nodes())\n",
    "        \n",
    "        if len(sub_df) < 10:  # Skip if not enough data\n",
    "            continue\n",
    "            \n",
    "        # PyG data\n",
    "        pyg_graph = from_networkx(G)\n",
    "        \n",
    "        # Prepare feature matrix - align with node order in the graph\n",
    "        node_to_idx = {node: i for i, node in enumerate(nodes)}\n",
    "        \n",
    "        # Make sure all nodes are in dataframe\n",
    "        nodes_in_df = [n for n in nodes if n in sub_df['txId'].values]\n",
    "        \n",
    "        if not nodes_in_df:\n",
    "            continue\n",
    "            \n",
    "        # Get features for these nodes\n",
    "        node_df = sub_df[sub_df['txId'].isin(nodes_in_df)]\n",
    "        feat_mat = node_df.set_index('txId')[feature_cols].fillna(0).values\n",
    "        \n",
    "        # Create node index to feature row mapping\n",
    "        node_to_feat_row = {node: i for i, node in enumerate(node_df['txId'])}\n",
    "        \n",
    "        # Create edge index for PyG\n",
    "        edge_list = list(G.edges())\n",
    "        src_nodes = [src for src, _ in edge_list if src in node_to_feat_row]\n",
    "        dst_nodes = [dst for _, dst in edge_list if dst in node_to_feat_row]\n",
    "        \n",
    "        if not src_nodes or not dst_nodes:\n",
    "            continue\n",
    "            \n",
    "        # Map to indices\n",
    "        src_indices = [node_to_idx[src] for src in src_nodes]\n",
    "        dst_indices = [node_to_idx[dst] for dst in dst_nodes]\n",
    "        \n",
    "        edge_index = torch.tensor([src_indices, dst_indices], dtype=torch.long)\n",
    "        \n",
    "        # Features and labels\n",
    "        x = torch.tensor(feat_mat, dtype=torch.float32)\n",
    "        \n",
    "        # Map labels: illicit=1, licit=0, unknown=-1\n",
    "        label_map = {'illicit': 1, 'licit': 0, 'unknown': -1}\n",
    "        y = node_df['class_label'].map(label_map).fillna(-1).astype(int).values\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "        # Setup train mask\n",
    "        train_mask = y >= 0  # Only labeled nodes\n",
    "        train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "        \n",
    "        if not train_mask.any():  # Skip if no labeled nodes\n",
    "            continue\n",
    "        \n",
    "        # Create PyG data object\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data.train_mask = train_mask\n",
    "        data = data.to(device)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = GCN(in_feats=len(feature_cols), hidden=128, out_feats=64).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Time step {time_step}, Epoch {epoch}: Loss {loss.item():.4f}\")\n",
    "        \n",
    "        # Get embeddings\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            emb = model(data.x, data.edge_index).cpu().numpy()\n",
    "        \n",
    "        # Create embedding dataframe\n",
    "        emb_df = pd.DataFrame(emb, columns=[f'gcn_{i}' for i in range(emb.shape[1])])\n",
    "        emb_df['txId'] = node_df['txId'].values\n",
    "        \n",
    "        all_embeddings.append(emb_df)\n",
    "    \n",
    "    # Combine all embeddings\n",
    "    if all_embeddings:\n",
    "        return pd.concat(all_embeddings, ignore_index=True)\n",
    "    else:\n",
    "        # Return empty DataFrame with correct columns\n",
    "        return pd.DataFrame(columns=['txId'] + [f'gcn_{i}' for i in range(64)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09138d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Train GCN and get embeddings\n",
    "print(\"Training GCN and getting embeddings for each time step...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "gcn_embeddings = train_gcn_get_embeddings(time_step_graphs, df, feature_cols, device=device)\n",
    "\n",
    "# 6. Merge all features\n",
    "print(\"Merging features...\")\n",
    "final_df = df.merge(gw_features, on='txId', how='left')\n",
    "final_df = final_df.merge(gcn_embeddings, on='txId', how='left')\n",
    "\n",
    "# 7. Train classifier (time-based split as in the paper)\n",
    "print(\"Training classifier...\")\n",
    "# Split by timestep (34 is the cutoff mentioned in the paper)\n",
    "train_mask = final_df['time_step'] <= 34\n",
    "test_mask = final_df['time_step'] > 34\n",
    "\n",
    "# Prepare features\n",
    "X_cols = feature_cols + [c for c in final_df.columns if c.startswith('gw_') or c.startswith('gcn_')]\n",
    "X = final_df[X_cols].fillna(0).values  # Fill NAs for any missing embeddings\n",
    "# Class 'illicit' is the target\n",
    "y = (final_df['class_label'] == 'illicit').astype(int).values\n",
    "\n",
    "X_train = X[train_mask]\n",
    "y_train = y[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "# Train Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"\\nTop 20 most important features:\")\n",
    "feature_names = X_cols\n",
    "for i in range(min(20, len(feature_names))):\n",
    "    print(f\"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
    "\n",
    "# Save results\n",
    "final_df.to_csv(os.path.join(data_path, 'elliptic_processed.csv'), index=False)\n",
    "print(f\"Processed data saved to {os.path.join(data_path, 'elliptic_processed.csv')}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88632b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c01e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbc894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1a88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "549dc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = nodes_df.drop(columns=['txId', 'time_step', 'class_label']).columns.to_list()\n",
    "### fÃ¼r mac \n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43226b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_nx_graph(edges):\n",
    "    \"\"\"Build a NetworkX graph from edge list.\"\"\"\n",
    "    G = nx.DiGraph()  # Directed graph as per the paper\n",
    "    G.add_edges_from(edges[['src', 'dst']].itertuples(index=False, name=None))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd9cca1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m G = build_nx_graph(edges_df)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m gcn_embeddings = \u001b[43mtrain_gcn_get_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmps_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_gcn_get_embeddings\u001b[39m\u001b[34m(G, df, feature_cols, epochs, lr, device)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Prepare edge index\u001b[39;00m\n\u001b[32m     12\u001b[39m edge_list = \u001b[38;5;28mlist\u001b[39m(G.edges())\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m edge_index = torch.tensor([[\u001b[43mnode_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m, node_ids.index(dst)] \u001b[38;5;28;01mfor\u001b[39;00m src, dst \u001b[38;5;129;01min\u001b[39;00m edge_list], dtype=torch.long).t()\n\u001b[32m     14\u001b[39m pyg_graph.edge_index = edge_index\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Labels: 1=illicit, 0=licit, -1=unknown\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Class '2' is illicit, '1' is licit, anything else is unknown\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "G = build_nx_graph(edges_df)\n",
    "\n",
    "gcn_embeddings = train_gcn_get_embeddings(G, nodes_df, feature_cols, device=mps_device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # 4. Compute GuiltyWalker features\n",
    "    print(\"Computing GuiltyWalker features...\")\n",
    "    gw_features = guilty_walker_features(G, labels)\n",
    "    \n",
    "    # 5. Train GCN and get embeddings\n",
    "    print(\"Training GCN and getting embeddings...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    gcn_embeddings = train_gcn_get_embeddings(G, df, feature_cols, device=device)\n",
    "    \n",
    "    # 6. Merge all features\n",
    "    print(\"Merging features...\")\n",
    "    final_df = df.merge(gw_features, on='txId', how='left')\n",
    "    final_df = final_df.merge(gcn_embeddings, on='txId', how='left')\n",
    "    \n",
    "    # 7. Train classifier (time-based split as in the paper)\n",
    "    print(\"Training classifier...\")\n",
    "    # Split by timestep (34 is the cutoff mentioned in the paper)\n",
    "    train_mask = final_df['time_step'] <= 34\n",
    "    test_mask = final_df['time_step'] > 34\n",
    "    \n",
    "    # Prepare features\n",
    "    X_cols = feature_cols + [c for c in final_df.columns if c.startswith('gw_') or c.startswith('gcn_')]\n",
    "    X = final_df[X_cols].values\n",
    "    # Class '2' is illicit\n",
    "    y = (final_df['class_label'] == '2').astype(int).values\n",
    "    \n",
    "    X_train = X[train_mask]\n",
    "    y_train = y[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_test = y[test_mask]\n",
    "    \n",
    "    # Train Random Forest\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
