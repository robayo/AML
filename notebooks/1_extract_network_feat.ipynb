{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94367b78",
   "metadata": {},
   "source": [
    "# Data Exploration: Elliptic Dataset\n",
    "# Augmentate network features\n",
    "https://www.kaggle.com/datasets/ellipticco/elliptic-data-set/data\n",
    "\n",
    "[1] Elliptic, www.elliptic.co.\n",
    "\n",
    "[2] M. Weber, G. Domeniconi, J. Chen, D. K. I. Weidele, C. Bellei, T. Robinson, C. E. Leiserson, \"Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics\", KDD ’19 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA.\n",
    "\n",
    "Description: The Elliptic Data Set maps Bitcoin transactions to real entities belonging to licit categories (exchanges, wallet providers, miners, licit services, etc.) versus illicit ones (scams, malware, terrorist organizations, ransomware, Ponzi schemes, etc.). The task on the dataset is to classify the illicit and licit nodes in the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "851d1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from src.data.load_data import load_elliptic_dataset\n",
    "from src.visualization.graphs import plot_transaction_graph\n",
    "from src.data.preprocess import corr_with_binary_labels\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "from typing import List, Dict\n",
    "from src.features.network_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0882558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3443bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/raw/'\n",
    "nodes_df, edges_df = load_elliptic_dataset(DATA_PATH)\n",
    "nodes_df['class_label'] = nodes_df['class_label'].replace(['1', '2', 'unknown'], ['illicit', 'licit', 'unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d984b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x176d0a2f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ad8d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 203769 nodes and 234355 edges\n",
      "Building time step graphs...\n",
      "Created 49 separate graphs for different time steps\n"
     ]
    }
   ],
   "source": [
    "G = build_nx_graph(edges_df)\n",
    "print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "labels = create_label_dict(nodes_df)\n",
    "print(\"Building time step graphs...\")\n",
    "time_step_graphs = build_time_step_graphs(edges_df, nodes_df)\n",
    "print(f\"Created {len(time_step_graphs)} separate graphs for different time steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04f6fdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing GuiltyWalker features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing time steps: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [07:01<00:00,  8.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# 4. Compute GuiltyWalker features\n",
    "print(\"Computing GuiltyWalker features...\")\n",
    "gw_features = guilty_walker_features(nodes_df, time_step_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7467ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "txId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gw_hit_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gw_min_step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gw_avg_step",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gw_unique_illicit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class_label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cbd7d3fc-3e00-4a1a-966b-25694623aaa5",
       "rows": [
        [
         "907",
         "232629023",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "1361",
         "230389796",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "2718",
         "17387772",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "2815",
         "232947878",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "3423",
         "16754007",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "4881",
         "231990430",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "5037",
         "232014511",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "5120",
         "24141114",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "5438",
         "62195631",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "6255",
         "24155910",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "7158",
         "16742787",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "7409",
         "231990435",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "7418",
         "17796937",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "7439",
         "184703182",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "7543",
         "16753577",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "7714",
         "232345692",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "7811",
         "3205536",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "8009",
         "115643001",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "8103",
         "310048974",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "8529",
         "310399847",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "8881",
         "286784958",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "9330",
         "289269312",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "10237",
         "258624857",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "10498",
         "309924066",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "10699",
         "286784427",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "10935",
         "289270308",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "11025",
         "312106094",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "11348",
         "312334552",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "11655",
         "212659519",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "11988",
         "286654752",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "12086",
         "313900565",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "12199",
         "296057714",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "12293",
         "310043610",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "12342",
         "286756215",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "12382",
         "310524772",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "15180",
         "244662723",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "15690",
         "245140933",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "16717",
         "245294955",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "16950",
         "245420039",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "17069",
         "245715541",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "17740",
         "27742555",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "17866",
         "245146113",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "18265",
         "246036358",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "18421",
         "245712851",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "18427",
         "245146107",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "18901",
         "245231973",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "19197",
         "86739424",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "19502",
         "87690267",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "19635",
         "45751341",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ],
        [
         "19917",
         "16809915",
         "0.0",
         "51",
         "51.0",
         "0",
         "illicit"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4545
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>gw_hit_ratio</th>\n",
       "      <th>gw_min_step</th>\n",
       "      <th>gw_avg_step</th>\n",
       "      <th>gw_unique_illicit</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>232629023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>230389796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>17387772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>232947878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>16754007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203685</th>\n",
       "      <td>159043651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203708</th>\n",
       "      <td>158360779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203736</th>\n",
       "      <td>159028476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203759</th>\n",
       "      <td>158375075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203766</th>\n",
       "      <td>158375402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>illicit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4545 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             txId  gw_hit_ratio  gw_min_step  gw_avg_step  gw_unique_illicit  \\\n",
       "907     232629023           0.0           51         51.0                  0   \n",
       "1361    230389796           0.0           51         51.0                  0   \n",
       "2718     17387772           0.0           51         51.0                  0   \n",
       "2815    232947878           0.0           51         51.0                  0   \n",
       "3423     16754007           0.0           51         51.0                  0   \n",
       "...           ...           ...          ...          ...                ...   \n",
       "203685  159043651           0.0           51         51.0                  0   \n",
       "203708  158360779           0.0           51         51.0                  0   \n",
       "203736  159028476           0.0           51         51.0                  0   \n",
       "203759  158375075           0.0           51         51.0                  0   \n",
       "203766  158375402           0.0           51         51.0                  0   \n",
       "\n",
       "       class_label  \n",
       "907        illicit  \n",
       "1361       illicit  \n",
       "2718       illicit  \n",
       "2815       illicit  \n",
       "3423       illicit  \n",
       "...            ...  \n",
       "203685     illicit  \n",
       "203708     illicit  \n",
       "203736     illicit  \n",
       "203759     illicit  \n",
       "203766     illicit  \n",
       "\n",
       "[4545 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_features.merge(nodes_df[['txId', 'class_label']], on = 'txId').query('class_label == \"illicit\" & gw_avg_step != 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9eb9ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:   0%|                                                                                                                                              | 0/49 [00:00<?, ?it/s]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 1, Epoch 0: Loss 9.2096\n",
      "Time step 1, Epoch 10: Loss 1.3408\n",
      "Time step 1, Epoch 20: Loss 0.3778\n",
      "Time step 1, Epoch 30: Loss 0.1554\n",
      "Time step 1, Epoch 40: Loss 0.0971\n",
      "Time step 1, Epoch 50: Loss 0.0733\n",
      "Time step 1, Epoch 60: Loss 0.0591\n",
      "Time step 1, Epoch 70: Loss 0.0531\n",
      "Time step 1, Epoch 80: Loss 0.0442\n",
      "Time step 1, Epoch 90: Loss 0.0450\n",
      "Time step 1, Epoch 100: Loss 0.0406\n",
      "Time step 1, Epoch 110: Loss 0.0388\n",
      "Time step 1, Epoch 120: Loss 0.0367\n",
      "Time step 1, Epoch 130: Loss 0.0313\n",
      "Time step 1, Epoch 140: Loss 0.0301\n",
      "Time step 1, Epoch 150: Loss 0.0279\n",
      "Time step 1, Epoch 160: Loss 0.0310\n",
      "Time step 1, Epoch 170: Loss 0.0255\n",
      "Time step 1, Epoch 180: Loss 0.0265\n",
      "Time step 1, Epoch 190: Loss 0.0228\n",
      "Time step 1, Epoch 200: Loss 0.0230\n",
      "Time step 1, Epoch 210: Loss 0.0245\n",
      "Time step 1, Epoch 220: Loss 0.0232\n",
      "Time step 1, Epoch 230: Loss 0.0191\n",
      "Time step 1, Epoch 240: Loss 0.0222\n",
      "Time step 1, Epoch 250: Loss 0.0188\n",
      "Time step 1, Epoch 260: Loss 0.0192\n",
      "Time step 1, Epoch 270: Loss 0.0173\n",
      "Time step 1, Epoch 280: Loss 0.0180\n",
      "Time step 1, Epoch 290: Loss 0.0186\n",
      "Time step 1, Epoch 300: Loss 0.0177\n",
      "Time step 1, Epoch 310: Loss 0.0158\n",
      "Time step 1, Epoch 320: Loss 0.0158\n",
      "Time step 1, Epoch 330: Loss 0.0144\n",
      "Time step 1, Epoch 340: Loss 0.0146\n",
      "Time step 1, Epoch 350: Loss 0.0156\n",
      "Time step 1, Epoch 360: Loss 0.0144\n",
      "Time step 1, Epoch 370: Loss 0.0132\n",
      "Time step 1, Epoch 380: Loss 0.0142\n",
      "Time step 1, Epoch 390: Loss 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:   2%|██▋                                                                                                                                   | 1/49 [00:06<05:20,  6.67s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 2, Epoch 0: Loss 5.7882\n",
      "Time step 2, Epoch 10: Loss 1.3592\n",
      "Time step 2, Epoch 20: Loss 0.3977\n",
      "Time step 2, Epoch 30: Loss 0.1860\n",
      "Time step 2, Epoch 40: Loss 0.1350\n",
      "Time step 2, Epoch 50: Loss 0.0960\n",
      "Time step 2, Epoch 60: Loss 0.0768\n",
      "Time step 2, Epoch 70: Loss 0.0618\n",
      "Time step 2, Epoch 80: Loss 0.0558\n",
      "Time step 2, Epoch 90: Loss 0.0489\n",
      "Time step 2, Epoch 100: Loss 0.0428\n",
      "Time step 2, Epoch 110: Loss 0.0395\n",
      "Time step 2, Epoch 120: Loss 0.0371\n",
      "Time step 2, Epoch 130: Loss 0.0317\n",
      "Time step 2, Epoch 140: Loss 0.0307\n",
      "Time step 2, Epoch 150: Loss 0.0291\n",
      "Time step 2, Epoch 160: Loss 0.0268\n",
      "Time step 2, Epoch 170: Loss 0.0241\n",
      "Time step 2, Epoch 180: Loss 0.0250\n",
      "Time step 2, Epoch 190: Loss 0.0220\n",
      "Time step 2, Epoch 200: Loss 0.0205\n",
      "Time step 2, Epoch 210: Loss 0.0210\n",
      "Time step 2, Epoch 220: Loss 0.0181\n",
      "Time step 2, Epoch 230: Loss 0.0168\n",
      "Time step 2, Epoch 240: Loss 0.0146\n",
      "Time step 2, Epoch 250: Loss 0.0194\n",
      "Time step 2, Epoch 260: Loss 0.0143\n",
      "Time step 2, Epoch 270: Loss 0.0151\n",
      "Time step 2, Epoch 280: Loss 0.0134\n",
      "Time step 2, Epoch 290: Loss 0.0118\n",
      "Time step 2, Epoch 300: Loss 0.0127\n",
      "Time step 2, Epoch 310: Loss 0.0112\n",
      "Time step 2, Epoch 320: Loss 0.0095\n",
      "Time step 2, Epoch 330: Loss 0.0144\n",
      "Time step 2, Epoch 340: Loss 0.0085\n",
      "Time step 2, Epoch 350: Loss 0.0114\n",
      "Time step 2, Epoch 360: Loss 0.0080\n",
      "Time step 2, Epoch 370: Loss 0.0098\n",
      "Time step 2, Epoch 380: Loss 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:   4%|█████▍                                                                                                                                | 2/49 [00:10<03:57,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 2, Epoch 390: Loss 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 3, Epoch 0: Loss 5.4973\n",
      "Time step 3, Epoch 10: Loss 2.1225\n",
      "Time step 3, Epoch 20: Loss 0.6903\n",
      "Time step 3, Epoch 30: Loss 0.2795\n",
      "Time step 3, Epoch 40: Loss 0.1396\n",
      "Time step 3, Epoch 50: Loss 0.0944\n",
      "Time step 3, Epoch 60: Loss 0.0778\n",
      "Time step 3, Epoch 70: Loss 0.0635\n",
      "Time step 3, Epoch 80: Loss 0.0451\n",
      "Time step 3, Epoch 90: Loss 0.0465\n",
      "Time step 3, Epoch 100: Loss 0.0416\n",
      "Time step 3, Epoch 110: Loss 0.0370\n",
      "Time step 3, Epoch 120: Loss 0.0302\n",
      "Time step 3, Epoch 130: Loss 0.0309\n",
      "Time step 3, Epoch 140: Loss 0.0299\n",
      "Time step 3, Epoch 150: Loss 0.0280\n",
      "Time step 3, Epoch 160: Loss 0.0268\n",
      "Time step 3, Epoch 170: Loss 0.0267\n",
      "Time step 3, Epoch 180: Loss 0.0263\n",
      "Time step 3, Epoch 190: Loss 0.0236\n",
      "Time step 3, Epoch 200: Loss 0.0195\n",
      "Time step 3, Epoch 210: Loss 0.0191\n",
      "Time step 3, Epoch 220: Loss 0.0180\n",
      "Time step 3, Epoch 230: Loss 0.0181\n",
      "Time step 3, Epoch 240: Loss 0.0157\n",
      "Time step 3, Epoch 250: Loss 0.0138\n",
      "Time step 3, Epoch 260: Loss 0.0165\n",
      "Time step 3, Epoch 270: Loss 0.0182\n",
      "Time step 3, Epoch 280: Loss 0.0170\n",
      "Time step 3, Epoch 290: Loss 0.0137\n",
      "Time step 3, Epoch 300: Loss 0.0123\n",
      "Time step 3, Epoch 310: Loss 0.0139\n",
      "Time step 3, Epoch 320: Loss 0.0145\n",
      "Time step 3, Epoch 330: Loss 0.0148\n",
      "Time step 3, Epoch 340: Loss 0.0122\n",
      "Time step 3, Epoch 350: Loss 0.0118\n",
      "Time step 3, Epoch 360: Loss 0.0116\n",
      "Time step 3, Epoch 370: Loss 0.0104\n",
      "Time step 3, Epoch 380: Loss 0.0124\n",
      "Time step 3, Epoch 390: Loss 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:   6%|████████▏                                                                                                                             | 3/49 [00:15<03:55,  5.12s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 4, Epoch 0: Loss 5.3910\n",
      "Time step 4, Epoch 10: Loss 1.5258\n",
      "Time step 4, Epoch 20: Loss 0.4709\n",
      "Time step 4, Epoch 30: Loss 0.2627\n",
      "Time step 4, Epoch 40: Loss 0.1871\n",
      "Time step 4, Epoch 50: Loss 0.1347\n",
      "Time step 4, Epoch 60: Loss 0.1122\n",
      "Time step 4, Epoch 70: Loss 0.0946\n",
      "Time step 4, Epoch 80: Loss 0.0906\n",
      "Time step 4, Epoch 90: Loss 0.0744\n",
      "Time step 4, Epoch 100: Loss 0.0701\n",
      "Time step 4, Epoch 110: Loss 0.0651\n",
      "Time step 4, Epoch 120: Loss 0.0625\n",
      "Time step 4, Epoch 130: Loss 0.0613\n",
      "Time step 4, Epoch 140: Loss 0.0531\n",
      "Time step 4, Epoch 150: Loss 0.0539\n",
      "Time step 4, Epoch 160: Loss 0.0508\n",
      "Time step 4, Epoch 170: Loss 0.0455\n",
      "Time step 4, Epoch 180: Loss 0.0397\n",
      "Time step 4, Epoch 190: Loss 0.0442\n",
      "Time step 4, Epoch 200: Loss 0.0386\n",
      "Time step 4, Epoch 210: Loss 0.0358\n",
      "Time step 4, Epoch 220: Loss 0.0346\n",
      "Time step 4, Epoch 230: Loss 0.0330\n",
      "Time step 4, Epoch 240: Loss 0.0294\n",
      "Time step 4, Epoch 250: Loss 0.0290\n",
      "Time step 4, Epoch 260: Loss 0.0257\n",
      "Time step 4, Epoch 270: Loss 0.0270\n",
      "Time step 4, Epoch 280: Loss 0.0228\n",
      "Time step 4, Epoch 290: Loss 0.0282\n",
      "Time step 4, Epoch 300: Loss 0.0224\n",
      "Time step 4, Epoch 310: Loss 0.0203\n",
      "Time step 4, Epoch 320: Loss 0.0226\n",
      "Time step 4, Epoch 330: Loss 0.0219\n",
      "Time step 4, Epoch 340: Loss 0.0211\n",
      "Time step 4, Epoch 350: Loss 0.0222\n",
      "Time step 4, Epoch 360: Loss 0.0205\n",
      "Time step 4, Epoch 370: Loss 0.0173\n",
      "Time step 4, Epoch 380: Loss 0.0193\n",
      "Time step 4, Epoch 390: Loss 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:   8%|██████████▉                                                                                                                           | 4/49 [00:20<03:40,  4.91s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 5, Epoch 0: Loss 5.0252\n",
      "Time step 5, Epoch 10: Loss 1.1389\n",
      "Time step 5, Epoch 20: Loss 0.3518\n",
      "Time step 5, Epoch 30: Loss 0.1498\n",
      "Time step 5, Epoch 40: Loss 0.0876\n",
      "Time step 5, Epoch 50: Loss 0.0599\n",
      "Time step 5, Epoch 60: Loss 0.0441\n",
      "Time step 5, Epoch 70: Loss 0.0365\n",
      "Time step 5, Epoch 80: Loss 0.0313\n",
      "Time step 5, Epoch 90: Loss 0.0287\n",
      "Time step 5, Epoch 100: Loss 0.0240\n",
      "Time step 5, Epoch 110: Loss 0.0211\n",
      "Time step 5, Epoch 120: Loss 0.0205\n",
      "Time step 5, Epoch 130: Loss 0.0182\n",
      "Time step 5, Epoch 140: Loss 0.0156\n",
      "Time step 5, Epoch 150: Loss 0.0161\n",
      "Time step 5, Epoch 160: Loss 0.0164\n",
      "Time step 5, Epoch 170: Loss 0.0129\n",
      "Time step 5, Epoch 180: Loss 0.0114\n",
      "Time step 5, Epoch 190: Loss 0.0104\n",
      "Time step 5, Epoch 200: Loss 0.0108\n",
      "Time step 5, Epoch 210: Loss 0.0095\n",
      "Time step 5, Epoch 220: Loss 0.0099\n",
      "Time step 5, Epoch 230: Loss 0.0088\n",
      "Time step 5, Epoch 240: Loss 0.0076\n",
      "Time step 5, Epoch 250: Loss 0.0076\n",
      "Time step 5, Epoch 260: Loss 0.0068\n",
      "Time step 5, Epoch 270: Loss 0.0090\n",
      "Time step 5, Epoch 280: Loss 0.0071\n",
      "Time step 5, Epoch 290: Loss 0.0073\n",
      "Time step 5, Epoch 300: Loss 0.0071\n",
      "Time step 5, Epoch 310: Loss 0.0055\n",
      "Time step 5, Epoch 320: Loss 0.0056\n",
      "Time step 5, Epoch 330: Loss 0.0054\n",
      "Time step 5, Epoch 340: Loss 0.0050\n",
      "Time step 5, Epoch 350: Loss 0.0045\n",
      "Time step 5, Epoch 360: Loss 0.0054\n",
      "Time step 5, Epoch 370: Loss 0.0041\n",
      "Time step 5, Epoch 380: Loss 0.0050\n",
      "Time step 5, Epoch 390: Loss 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  10%|█████████████▋                                                                                                                        | 5/49 [00:25<03:44,  5.10s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 6, Epoch 0: Loss 4.5829\n",
      "Time step 6, Epoch 10: Loss 1.1081\n",
      "Time step 6, Epoch 20: Loss 0.3016\n",
      "Time step 6, Epoch 30: Loss 0.1459\n",
      "Time step 6, Epoch 40: Loss 0.0818\n",
      "Time step 6, Epoch 50: Loss 0.0625\n",
      "Time step 6, Epoch 60: Loss 0.0502\n",
      "Time step 6, Epoch 70: Loss 0.0375\n",
      "Time step 6, Epoch 80: Loss 0.0307\n",
      "Time step 6, Epoch 90: Loss 0.0284\n",
      "Time step 6, Epoch 100: Loss 0.0239\n",
      "Time step 6, Epoch 110: Loss 0.0176\n",
      "Time step 6, Epoch 120: Loss 0.0159\n",
      "Time step 6, Epoch 130: Loss 0.0159\n",
      "Time step 6, Epoch 140: Loss 0.0126\n",
      "Time step 6, Epoch 150: Loss 0.0113\n",
      "Time step 6, Epoch 160: Loss 0.0085\n",
      "Time step 6, Epoch 170: Loss 0.0085\n",
      "Time step 6, Epoch 180: Loss 0.0059\n",
      "Time step 6, Epoch 190: Loss 0.0074\n",
      "Time step 6, Epoch 200: Loss 0.0068\n",
      "Time step 6, Epoch 210: Loss 0.0060\n",
      "Time step 6, Epoch 220: Loss 0.0074\n",
      "Time step 6, Epoch 230: Loss 0.0050\n",
      "Time step 6, Epoch 240: Loss 0.0048\n",
      "Time step 6, Epoch 250: Loss 0.0065\n",
      "Time step 6, Epoch 260: Loss 0.0042\n",
      "Time step 6, Epoch 270: Loss 0.0035\n",
      "Time step 6, Epoch 280: Loss 0.0038\n",
      "Time step 6, Epoch 290: Loss 0.0038\n",
      "Time step 6, Epoch 300: Loss 0.0038\n",
      "Time step 6, Epoch 310: Loss 0.0033\n",
      "Time step 6, Epoch 320: Loss 0.0035\n",
      "Time step 6, Epoch 330: Loss 0.0033\n",
      "Time step 6, Epoch 340: Loss 0.0030\n",
      "Time step 6, Epoch 350: Loss 0.0026\n",
      "Time step 6, Epoch 360: Loss 0.0026\n",
      "Time step 6, Epoch 370: Loss 0.0033\n",
      "Time step 6, Epoch 380: Loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  12%|████████████████▍                                                                                                                     | 6/49 [00:29<03:21,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 6, Epoch 390: Loss 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 7, Epoch 0: Loss 4.2789\n",
      "Time step 7, Epoch 10: Loss 1.3153\n",
      "Time step 7, Epoch 20: Loss 0.6438\n",
      "Time step 7, Epoch 30: Loss 0.3772\n",
      "Time step 7, Epoch 40: Loss 0.2499\n",
      "Time step 7, Epoch 50: Loss 0.1968\n",
      "Time step 7, Epoch 60: Loss 0.1686\n",
      "Time step 7, Epoch 70: Loss 0.1429\n",
      "Time step 7, Epoch 80: Loss 0.1341\n",
      "Time step 7, Epoch 90: Loss 0.1271\n",
      "Time step 7, Epoch 100: Loss 0.1144\n",
      "Time step 7, Epoch 110: Loss 0.1019\n",
      "Time step 7, Epoch 120: Loss 0.0984\n",
      "Time step 7, Epoch 130: Loss 0.0953\n",
      "Time step 7, Epoch 140: Loss 0.0934\n",
      "Time step 7, Epoch 150: Loss 0.0843\n",
      "Time step 7, Epoch 160: Loss 0.0857\n",
      "Time step 7, Epoch 170: Loss 0.0834\n",
      "Time step 7, Epoch 180: Loss 0.0776\n",
      "Time step 7, Epoch 190: Loss 0.0781\n",
      "Time step 7, Epoch 200: Loss 0.0739\n",
      "Time step 7, Epoch 210: Loss 0.0683\n",
      "Time step 7, Epoch 220: Loss 0.0721\n",
      "Time step 7, Epoch 230: Loss 0.0668\n",
      "Time step 7, Epoch 240: Loss 0.0572\n",
      "Time step 7, Epoch 250: Loss 0.0626\n",
      "Time step 7, Epoch 260: Loss 0.0633\n",
      "Time step 7, Epoch 270: Loss 0.0613\n",
      "Time step 7, Epoch 280: Loss 0.0548\n",
      "Time step 7, Epoch 290: Loss 0.0521\n",
      "Time step 7, Epoch 300: Loss 0.0531\n",
      "Time step 7, Epoch 310: Loss 0.0519\n",
      "Time step 7, Epoch 320: Loss 0.0505\n",
      "Time step 7, Epoch 330: Loss 0.0537\n",
      "Time step 7, Epoch 340: Loss 0.0470\n",
      "Time step 7, Epoch 350: Loss 0.0468\n",
      "Time step 7, Epoch 360: Loss 0.0393\n",
      "Time step 7, Epoch 370: Loss 0.0434\n",
      "Time step 7, Epoch 380: Loss 0.0456\n",
      "Time step 7, Epoch 390: Loss 0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  14%|███████████████████▏                                                                                                                  | 7/49 [00:34<03:19,  4.75s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 8, Epoch 0: Loss 4.6182\n",
      "Time step 8, Epoch 10: Loss 1.2965\n",
      "Time step 8, Epoch 20: Loss 0.5440\n",
      "Time step 8, Epoch 30: Loss 0.3298\n",
      "Time step 8, Epoch 40: Loss 0.2330\n",
      "Time step 8, Epoch 50: Loss 0.1766\n",
      "Time step 8, Epoch 60: Loss 0.1556\n",
      "Time step 8, Epoch 70: Loss 0.1289\n",
      "Time step 8, Epoch 80: Loss 0.1158\n",
      "Time step 8, Epoch 90: Loss 0.1071\n",
      "Time step 8, Epoch 100: Loss 0.0919\n",
      "Time step 8, Epoch 110: Loss 0.0917\n",
      "Time step 8, Epoch 120: Loss 0.0854\n",
      "Time step 8, Epoch 130: Loss 0.0838\n",
      "Time step 8, Epoch 140: Loss 0.0843\n",
      "Time step 8, Epoch 150: Loss 0.0793\n",
      "Time step 8, Epoch 160: Loss 0.0655\n",
      "Time step 8, Epoch 170: Loss 0.0711\n",
      "Time step 8, Epoch 180: Loss 0.0621\n",
      "Time step 8, Epoch 190: Loss 0.0593\n",
      "Time step 8, Epoch 200: Loss 0.0594\n",
      "Time step 8, Epoch 210: Loss 0.0578\n",
      "Time step 8, Epoch 220: Loss 0.0509\n",
      "Time step 8, Epoch 230: Loss 0.0528\n",
      "Time step 8, Epoch 240: Loss 0.0529\n",
      "Time step 8, Epoch 250: Loss 0.0505\n",
      "Time step 8, Epoch 260: Loss 0.0503\n",
      "Time step 8, Epoch 270: Loss 0.0469\n",
      "Time step 8, Epoch 280: Loss 0.0475\n",
      "Time step 8, Epoch 290: Loss 0.0468\n",
      "Time step 8, Epoch 300: Loss 0.0402\n",
      "Time step 8, Epoch 310: Loss 0.0427\n",
      "Time step 8, Epoch 320: Loss 0.0407\n",
      "Time step 8, Epoch 330: Loss 0.0419\n",
      "Time step 8, Epoch 340: Loss 0.0348\n",
      "Time step 8, Epoch 350: Loss 0.0406\n",
      "Time step 8, Epoch 360: Loss 0.0371\n",
      "Time step 8, Epoch 370: Loss 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  16%|█████████████████████▉                                                                                                                | 8/49 [00:38<03:04,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 8, Epoch 380: Loss 0.0398\n",
      "Time step 8, Epoch 390: Loss 0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 9, Epoch 0: Loss 4.7945\n",
      "Time step 9, Epoch 10: Loss 2.5846\n",
      "Time step 9, Epoch 20: Loss 1.2795\n",
      "Time step 9, Epoch 30: Loss 0.7230\n",
      "Time step 9, Epoch 40: Loss 0.5126\n",
      "Time step 9, Epoch 50: Loss 0.4305\n",
      "Time step 9, Epoch 60: Loss 0.3940\n",
      "Time step 9, Epoch 70: Loss 0.3653\n",
      "Time step 9, Epoch 80: Loss 0.3416\n",
      "Time step 9, Epoch 90: Loss 0.3268\n",
      "Time step 9, Epoch 100: Loss 0.3074\n",
      "Time step 9, Epoch 110: Loss 0.2988\n",
      "Time step 9, Epoch 120: Loss 0.2735\n",
      "Time step 9, Epoch 130: Loss 0.2736\n",
      "Time step 9, Epoch 140: Loss 0.2675\n",
      "Time step 9, Epoch 150: Loss 0.2571\n",
      "Time step 9, Epoch 160: Loss 0.2463\n",
      "Time step 9, Epoch 170: Loss 0.2425\n",
      "Time step 9, Epoch 180: Loss 0.2373\n",
      "Time step 9, Epoch 190: Loss 0.2299\n",
      "Time step 9, Epoch 200: Loss 0.2216\n",
      "Time step 9, Epoch 210: Loss 0.2085\n",
      "Time step 9, Epoch 220: Loss 0.2137\n",
      "Time step 9, Epoch 230: Loss 0.2143\n",
      "Time step 9, Epoch 240: Loss 0.1950\n",
      "Time step 9, Epoch 250: Loss 0.1958\n",
      "Time step 9, Epoch 260: Loss 0.1864\n",
      "Time step 9, Epoch 270: Loss 0.1835\n",
      "Time step 9, Epoch 280: Loss 0.1757\n",
      "Time step 9, Epoch 290: Loss 0.1747\n",
      "Time step 9, Epoch 300: Loss 0.1696\n",
      "Time step 9, Epoch 310: Loss 0.1629\n",
      "Time step 9, Epoch 320: Loss 0.1599\n",
      "Time step 9, Epoch 330: Loss 0.1655\n",
      "Time step 9, Epoch 340: Loss 0.1570\n",
      "Time step 9, Epoch 350: Loss 0.1599\n",
      "Time step 9, Epoch 360: Loss 0.1586\n",
      "Time step 9, Epoch 370: Loss 0.1516\n",
      "Time step 9, Epoch 380: Loss 0.1413\n",
      "Time step 9, Epoch 390: Loss 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  18%|████████████████████████▌                                                                                                             | 9/49 [00:42<02:56,  4.41s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 10, Epoch 0: Loss 4.9699\n",
      "Time step 10, Epoch 10: Loss 1.3958\n",
      "Time step 10, Epoch 20: Loss 0.6082\n",
      "Time step 10, Epoch 30: Loss 0.2981\n",
      "Time step 10, Epoch 40: Loss 0.1743\n",
      "Time step 10, Epoch 50: Loss 0.1204\n",
      "Time step 10, Epoch 60: Loss 0.0910\n",
      "Time step 10, Epoch 70: Loss 0.0767\n",
      "Time step 10, Epoch 80: Loss 0.0685\n",
      "Time step 10, Epoch 90: Loss 0.0601\n",
      "Time step 10, Epoch 100: Loss 0.0542\n",
      "Time step 10, Epoch 110: Loss 0.0526\n",
      "Time step 10, Epoch 120: Loss 0.0530\n",
      "Time step 10, Epoch 130: Loss 0.0492\n",
      "Time step 10, Epoch 140: Loss 0.0470\n",
      "Time step 10, Epoch 150: Loss 0.0455\n",
      "Time step 10, Epoch 160: Loss 0.0461\n",
      "Time step 10, Epoch 170: Loss 0.0416\n",
      "Time step 10, Epoch 180: Loss 0.0429\n",
      "Time step 10, Epoch 190: Loss 0.0429\n",
      "Time step 10, Epoch 200: Loss 0.0409\n",
      "Time step 10, Epoch 210: Loss 0.0409\n",
      "Time step 10, Epoch 220: Loss 0.0365\n",
      "Time step 10, Epoch 230: Loss 0.0368\n",
      "Time step 10, Epoch 240: Loss 0.0357\n",
      "Time step 10, Epoch 250: Loss 0.0377\n",
      "Time step 10, Epoch 260: Loss 0.0368\n",
      "Time step 10, Epoch 270: Loss 0.0358\n",
      "Time step 10, Epoch 280: Loss 0.0331\n",
      "Time step 10, Epoch 290: Loss 0.0323\n",
      "Time step 10, Epoch 300: Loss 0.0347\n",
      "Time step 10, Epoch 310: Loss 0.0345\n",
      "Time step 10, Epoch 320: Loss 0.0307\n",
      "Time step 10, Epoch 330: Loss 0.0309\n",
      "Time step 10, Epoch 340: Loss 0.0324\n",
      "Time step 10, Epoch 350: Loss 0.0307\n",
      "Time step 10, Epoch 360: Loss 0.0272\n",
      "Time step 10, Epoch 370: Loss 0.0293\n",
      "Time step 10, Epoch 380: Loss 0.0278\n",
      "Time step 10, Epoch 390: Loss 0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  20%|███████████████████████████▏                                                                                                         | 10/49 [00:48<03:04,  4.74s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 11, Epoch 0: Loss 5.1044\n",
      "Time step 11, Epoch 10: Loss 2.2071\n",
      "Time step 11, Epoch 20: Loss 1.1534\n",
      "Time step 11, Epoch 30: Loss 0.6190\n",
      "Time step 11, Epoch 40: Loss 0.4008\n",
      "Time step 11, Epoch 50: Loss 0.2916\n",
      "Time step 11, Epoch 60: Loss 0.2554\n",
      "Time step 11, Epoch 70: Loss 0.2415\n",
      "Time step 11, Epoch 80: Loss 0.2202\n",
      "Time step 11, Epoch 90: Loss 0.2000\n",
      "Time step 11, Epoch 100: Loss 0.1856\n",
      "Time step 11, Epoch 110: Loss 0.1776\n",
      "Time step 11, Epoch 120: Loss 0.1818\n",
      "Time step 11, Epoch 130: Loss 0.1638\n",
      "Time step 11, Epoch 140: Loss 0.1511\n",
      "Time step 11, Epoch 150: Loss 0.1473\n",
      "Time step 11, Epoch 160: Loss 0.1491\n",
      "Time step 11, Epoch 170: Loss 0.1324\n",
      "Time step 11, Epoch 180: Loss 0.1318\n",
      "Time step 11, Epoch 190: Loss 0.1275\n",
      "Time step 11, Epoch 200: Loss 0.1147\n",
      "Time step 11, Epoch 210: Loss 0.1216\n",
      "Time step 11, Epoch 220: Loss 0.1200\n",
      "Time step 11, Epoch 230: Loss 0.1147\n",
      "Time step 11, Epoch 240: Loss 0.1044\n",
      "Time step 11, Epoch 250: Loss 0.1087\n",
      "Time step 11, Epoch 260: Loss 0.0989\n",
      "Time step 11, Epoch 270: Loss 0.0997\n",
      "Time step 11, Epoch 280: Loss 0.0937\n",
      "Time step 11, Epoch 290: Loss 0.0929\n",
      "Time step 11, Epoch 300: Loss 0.0940\n",
      "Time step 11, Epoch 310: Loss 0.0918\n",
      "Time step 11, Epoch 320: Loss 0.0807\n",
      "Time step 11, Epoch 330: Loss 0.0782\n",
      "Time step 11, Epoch 340: Loss 0.0820\n",
      "Time step 11, Epoch 350: Loss 0.0826\n",
      "Time step 11, Epoch 360: Loss 0.0749\n",
      "Time step 11, Epoch 370: Loss 0.0747\n",
      "Time step 11, Epoch 380: Loss 0.0840\n",
      "Time step 11, Epoch 390: Loss 0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  22%|█████████████████████████████▊                                                                                                       | 11/49 [00:52<02:54,  4.59s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 12, Epoch 0: Loss 5.5199\n",
      "Time step 12, Epoch 10: Loss 1.4276\n",
      "Time step 12, Epoch 20: Loss 0.8328\n",
      "Time step 12, Epoch 30: Loss 0.4802\n",
      "Time step 12, Epoch 40: Loss 0.3020\n",
      "Time step 12, Epoch 50: Loss 0.2093\n",
      "Time step 12, Epoch 60: Loss 0.1523\n",
      "Time step 12, Epoch 70: Loss 0.1192\n",
      "Time step 12, Epoch 80: Loss 0.1082\n",
      "Time step 12, Epoch 90: Loss 0.0979\n",
      "Time step 12, Epoch 100: Loss 0.0826\n",
      "Time step 12, Epoch 110: Loss 0.0772\n",
      "Time step 12, Epoch 120: Loss 0.0703\n",
      "Time step 12, Epoch 130: Loss 0.0700\n",
      "Time step 12, Epoch 140: Loss 0.0581\n",
      "Time step 12, Epoch 150: Loss 0.0529\n",
      "Time step 12, Epoch 160: Loss 0.0551\n",
      "Time step 12, Epoch 170: Loss 0.0485\n",
      "Time step 12, Epoch 180: Loss 0.0420\n",
      "Time step 12, Epoch 190: Loss 0.0467\n",
      "Time step 12, Epoch 200: Loss 0.0416\n",
      "Time step 12, Epoch 210: Loss 0.0385\n",
      "Time step 12, Epoch 220: Loss 0.0363\n",
      "Time step 12, Epoch 230: Loss 0.0340\n",
      "Time step 12, Epoch 240: Loss 0.0282\n",
      "Time step 12, Epoch 250: Loss 0.0301\n",
      "Time step 12, Epoch 260: Loss 0.0243\n",
      "Time step 12, Epoch 270: Loss 0.0247\n",
      "Time step 12, Epoch 280: Loss 0.0216\n",
      "Time step 12, Epoch 290: Loss 0.0210\n",
      "Time step 12, Epoch 300: Loss 0.0199\n",
      "Time step 12, Epoch 310: Loss 0.0247\n",
      "Time step 12, Epoch 320: Loss 0.0201\n",
      "Time step 12, Epoch 330: Loss 0.0207\n",
      "Time step 12, Epoch 340: Loss 0.0149\n",
      "Time step 12, Epoch 350: Loss 0.0206\n",
      "Time step 12, Epoch 360: Loss 0.0220\n",
      "Time step 12, Epoch 370: Loss 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  24%|████████████████████████████████▌                                                                                                    | 12/49 [00:56<02:45,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 12, Epoch 380: Loss 0.0173\n",
      "Time step 12, Epoch 390: Loss 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 13, Epoch 0: Loss 5.0202\n",
      "Time step 13, Epoch 10: Loss 2.5324\n",
      "Time step 13, Epoch 20: Loss 1.4671\n",
      "Time step 13, Epoch 30: Loss 0.8620\n",
      "Time step 13, Epoch 40: Loss 0.5422\n",
      "Time step 13, Epoch 50: Loss 0.4117\n",
      "Time step 13, Epoch 60: Loss 0.3345\n",
      "Time step 13, Epoch 70: Loss 0.3004\n",
      "Time step 13, Epoch 80: Loss 0.2677\n",
      "Time step 13, Epoch 90: Loss 0.2472\n",
      "Time step 13, Epoch 100: Loss 0.2399\n",
      "Time step 13, Epoch 110: Loss 0.2279\n",
      "Time step 13, Epoch 120: Loss 0.2180\n",
      "Time step 13, Epoch 130: Loss 0.2103\n",
      "Time step 13, Epoch 140: Loss 0.1992\n",
      "Time step 13, Epoch 150: Loss 0.1806\n",
      "Time step 13, Epoch 160: Loss 0.1755\n",
      "Time step 13, Epoch 170: Loss 0.1690\n",
      "Time step 13, Epoch 180: Loss 0.1684\n",
      "Time step 13, Epoch 190: Loss 0.1545\n",
      "Time step 13, Epoch 200: Loss 0.1575\n",
      "Time step 13, Epoch 210: Loss 0.1427\n",
      "Time step 13, Epoch 220: Loss 0.1404\n",
      "Time step 13, Epoch 230: Loss 0.1451\n",
      "Time step 13, Epoch 240: Loss 0.1302\n",
      "Time step 13, Epoch 250: Loss 0.1376\n",
      "Time step 13, Epoch 260: Loss 0.1379\n",
      "Time step 13, Epoch 270: Loss 0.1332\n",
      "Time step 13, Epoch 280: Loss 0.1206\n",
      "Time step 13, Epoch 290: Loss 0.1160\n",
      "Time step 13, Epoch 300: Loss 0.1101\n",
      "Time step 13, Epoch 310: Loss 0.1108\n",
      "Time step 13, Epoch 320: Loss 0.1128\n",
      "Time step 13, Epoch 330: Loss 0.1114\n",
      "Time step 13, Epoch 340: Loss 0.1069\n",
      "Time step 13, Epoch 350: Loss 0.1041\n",
      "Time step 13, Epoch 360: Loss 0.1004\n",
      "Time step 13, Epoch 370: Loss 0.1021\n",
      "Time step 13, Epoch 380: Loss 0.1027\n",
      "Time step 13, Epoch 390: Loss 0.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  27%|███████████████████████████████████▎                                                                                                 | 13/49 [01:00<02:37,  4.38s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 14, Epoch 0: Loss 4.3347\n",
      "Time step 14, Epoch 10: Loss 1.7083\n",
      "Time step 14, Epoch 20: Loss 0.8947\n",
      "Time step 14, Epoch 30: Loss 0.5313\n",
      "Time step 14, Epoch 40: Loss 0.3170\n",
      "Time step 14, Epoch 50: Loss 0.2217\n",
      "Time step 14, Epoch 60: Loss 0.1860\n",
      "Time step 14, Epoch 70: Loss 0.1614\n",
      "Time step 14, Epoch 80: Loss 0.1405\n",
      "Time step 14, Epoch 90: Loss 0.1212\n",
      "Time step 14, Epoch 100: Loss 0.0982\n",
      "Time step 14, Epoch 110: Loss 0.0866\n",
      "Time step 14, Epoch 120: Loss 0.0998\n",
      "Time step 14, Epoch 130: Loss 0.0851\n",
      "Time step 14, Epoch 140: Loss 0.0802\n",
      "Time step 14, Epoch 150: Loss 0.0710\n",
      "Time step 14, Epoch 160: Loss 0.0681\n",
      "Time step 14, Epoch 170: Loss 0.0620\n",
      "Time step 14, Epoch 180: Loss 0.0628\n",
      "Time step 14, Epoch 190: Loss 0.0529\n",
      "Time step 14, Epoch 200: Loss 0.0512\n",
      "Time step 14, Epoch 210: Loss 0.0530\n",
      "Time step 14, Epoch 220: Loss 0.0499\n",
      "Time step 14, Epoch 230: Loss 0.0481\n",
      "Time step 14, Epoch 240: Loss 0.0432\n",
      "Time step 14, Epoch 250: Loss 0.0416\n",
      "Time step 14, Epoch 260: Loss 0.0385\n",
      "Time step 14, Epoch 270: Loss 0.0385\n",
      "Time step 14, Epoch 280: Loss 0.0403\n",
      "Time step 14, Epoch 290: Loss 0.0336\n",
      "Time step 14, Epoch 300: Loss 0.0327\n",
      "Time step 14, Epoch 310: Loss 0.0391\n",
      "Time step 14, Epoch 320: Loss 0.0270\n",
      "Time step 14, Epoch 330: Loss 0.0266\n",
      "Time step 14, Epoch 340: Loss 0.0253\n",
      "Time step 14, Epoch 350: Loss 0.0232\n",
      "Time step 14, Epoch 360: Loss 0.0285\n",
      "Time step 14, Epoch 370: Loss 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  29%|██████████████████████████████████████                                                                                               | 14/49 [01:04<02:27,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 14, Epoch 380: Loss 0.0284\n",
      "Time step 14, Epoch 390: Loss 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 15, Epoch 0: Loss 5.0116\n",
      "Time step 15, Epoch 10: Loss 2.4521\n",
      "Time step 15, Epoch 20: Loss 1.4130\n",
      "Time step 15, Epoch 30: Loss 0.7984\n",
      "Time step 15, Epoch 40: Loss 0.4593\n",
      "Time step 15, Epoch 50: Loss 0.3257\n",
      "Time step 15, Epoch 60: Loss 0.2554\n",
      "Time step 15, Epoch 70: Loss 0.2191\n",
      "Time step 15, Epoch 80: Loss 0.1952\n",
      "Time step 15, Epoch 90: Loss 0.1715\n",
      "Time step 15, Epoch 100: Loss 0.1572\n",
      "Time step 15, Epoch 110: Loss 0.1521\n",
      "Time step 15, Epoch 120: Loss 0.1494\n",
      "Time step 15, Epoch 130: Loss 0.1239\n",
      "Time step 15, Epoch 140: Loss 0.1295\n",
      "Time step 15, Epoch 150: Loss 0.1288\n",
      "Time step 15, Epoch 160: Loss 0.1189\n",
      "Time step 15, Epoch 170: Loss 0.1174\n",
      "Time step 15, Epoch 180: Loss 0.1079\n",
      "Time step 15, Epoch 190: Loss 0.1108\n",
      "Time step 15, Epoch 200: Loss 0.1020\n",
      "Time step 15, Epoch 210: Loss 0.0998\n",
      "Time step 15, Epoch 220: Loss 0.0974\n",
      "Time step 15, Epoch 230: Loss 0.0902\n",
      "Time step 15, Epoch 240: Loss 0.0837\n",
      "Time step 15, Epoch 250: Loss 0.0737\n",
      "Time step 15, Epoch 260: Loss 0.0784\n",
      "Time step 15, Epoch 270: Loss 0.0798\n",
      "Time step 15, Epoch 280: Loss 0.0819\n",
      "Time step 15, Epoch 290: Loss 0.0750\n",
      "Time step 15, Epoch 300: Loss 0.0758\n",
      "Time step 15, Epoch 310: Loss 0.0701\n",
      "Time step 15, Epoch 320: Loss 0.0654\n",
      "Time step 15, Epoch 330: Loss 0.0637\n",
      "Time step 15, Epoch 340: Loss 0.0608\n",
      "Time step 15, Epoch 350: Loss 0.0577\n",
      "Time step 15, Epoch 360: Loss 0.0575\n",
      "Time step 15, Epoch 370: Loss 0.0621\n",
      "Time step 15, Epoch 380: Loss 0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  31%|████████████████████████████████████████▋                                                                                            | 15/49 [01:08<02:21,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 15, Epoch 390: Loss 0.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 16, Epoch 0: Loss 4.6563\n",
      "Time step 16, Epoch 10: Loss 2.4490\n",
      "Time step 16, Epoch 20: Loss 1.3458\n",
      "Time step 16, Epoch 30: Loss 0.7365\n",
      "Time step 16, Epoch 40: Loss 0.4265\n",
      "Time step 16, Epoch 50: Loss 0.3120\n",
      "Time step 16, Epoch 60: Loss 0.2628\n",
      "Time step 16, Epoch 70: Loss 0.2363\n",
      "Time step 16, Epoch 80: Loss 0.2059\n",
      "Time step 16, Epoch 90: Loss 0.1836\n",
      "Time step 16, Epoch 100: Loss 0.1789\n",
      "Time step 16, Epoch 110: Loss 0.1621\n",
      "Time step 16, Epoch 120: Loss 0.1501\n",
      "Time step 16, Epoch 130: Loss 0.1460\n",
      "Time step 16, Epoch 140: Loss 0.1448\n",
      "Time step 16, Epoch 150: Loss 0.1359\n",
      "Time step 16, Epoch 160: Loss 0.1230\n",
      "Time step 16, Epoch 170: Loss 0.1244\n",
      "Time step 16, Epoch 180: Loss 0.1186\n",
      "Time step 16, Epoch 190: Loss 0.0970\n",
      "Time step 16, Epoch 200: Loss 0.1023\n",
      "Time step 16, Epoch 210: Loss 0.0972\n",
      "Time step 16, Epoch 220: Loss 0.0874\n",
      "Time step 16, Epoch 230: Loss 0.0849\n",
      "Time step 16, Epoch 240: Loss 0.0940\n",
      "Time step 16, Epoch 250: Loss 0.0821\n",
      "Time step 16, Epoch 260: Loss 0.0675\n",
      "Time step 16, Epoch 270: Loss 0.0809\n",
      "Time step 16, Epoch 280: Loss 0.0696\n",
      "Time step 16, Epoch 290: Loss 0.0694\n",
      "Time step 16, Epoch 300: Loss 0.0626\n",
      "Time step 16, Epoch 310: Loss 0.0710\n",
      "Time step 16, Epoch 320: Loss 0.0660\n",
      "Time step 16, Epoch 330: Loss 0.0569\n",
      "Time step 16, Epoch 340: Loss 0.0555\n",
      "Time step 16, Epoch 350: Loss 0.0598\n",
      "Time step 16, Epoch 360: Loss 0.0578\n",
      "Time step 16, Epoch 370: Loss 0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  33%|███████████████████████████████████████████▍                                                                                         | 16/49 [01:12<02:11,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 16, Epoch 380: Loss 0.0454\n",
      "Time step 16, Epoch 390: Loss 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 17, Epoch 0: Loss 3.6784\n",
      "Time step 17, Epoch 10: Loss 1.5710\n",
      "Time step 17, Epoch 20: Loss 0.8614\n",
      "Time step 17, Epoch 30: Loss 0.5022\n",
      "Time step 17, Epoch 40: Loss 0.3282\n",
      "Time step 17, Epoch 50: Loss 0.2596\n",
      "Time step 17, Epoch 60: Loss 0.2141\n",
      "Time step 17, Epoch 70: Loss 0.1833\n",
      "Time step 17, Epoch 80: Loss 0.1764\n",
      "Time step 17, Epoch 90: Loss 0.1548\n",
      "Time step 17, Epoch 100: Loss 0.1502\n",
      "Time step 17, Epoch 110: Loss 0.1431\n",
      "Time step 17, Epoch 120: Loss 0.1366\n",
      "Time step 17, Epoch 130: Loss 0.1235\n",
      "Time step 17, Epoch 140: Loss 0.1172\n",
      "Time step 17, Epoch 150: Loss 0.1302\n",
      "Time step 17, Epoch 160: Loss 0.1064\n",
      "Time step 17, Epoch 170: Loss 0.1072\n",
      "Time step 17, Epoch 180: Loss 0.1034\n",
      "Time step 17, Epoch 190: Loss 0.1039\n",
      "Time step 17, Epoch 200: Loss 0.0943\n",
      "Time step 17, Epoch 210: Loss 0.0895\n",
      "Time step 17, Epoch 220: Loss 0.0888\n",
      "Time step 17, Epoch 230: Loss 0.0827\n",
      "Time step 17, Epoch 240: Loss 0.0798\n",
      "Time step 17, Epoch 250: Loss 0.0787\n",
      "Time step 17, Epoch 260: Loss 0.0734\n",
      "Time step 17, Epoch 270: Loss 0.0710\n",
      "Time step 17, Epoch 280: Loss 0.0676\n",
      "Time step 17, Epoch 290: Loss 0.0693\n",
      "Time step 17, Epoch 300: Loss 0.0644\n",
      "Time step 17, Epoch 310: Loss 0.0603\n",
      "Time step 17, Epoch 320: Loss 0.0615\n",
      "Time step 17, Epoch 330: Loss 0.0623\n",
      "Time step 17, Epoch 340: Loss 0.0597\n",
      "Time step 17, Epoch 350: Loss 0.0543\n",
      "Time step 17, Epoch 360: Loss 0.0593\n",
      "Time step 17, Epoch 370: Loss 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  35%|██████████████████████████████████████████████▏                                                                                      | 17/49 [01:15<02:04,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 17, Epoch 380: Loss 0.0504\n",
      "Time step 17, Epoch 390: Loss 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 18, Epoch 0: Loss 4.4194\n",
      "Time step 18, Epoch 10: Loss 1.7092\n",
      "Time step 18, Epoch 20: Loss 1.0368\n",
      "Time step 18, Epoch 30: Loss 0.6533\n",
      "Time step 18, Epoch 40: Loss 0.4492\n",
      "Time step 18, Epoch 50: Loss 0.3159\n",
      "Time step 18, Epoch 60: Loss 0.2593\n",
      "Time step 18, Epoch 70: Loss 0.1976\n",
      "Time step 18, Epoch 80: Loss 0.1871\n",
      "Time step 18, Epoch 90: Loss 0.1708\n",
      "Time step 18, Epoch 100: Loss 0.1617\n",
      "Time step 18, Epoch 110: Loss 0.1371\n",
      "Time step 18, Epoch 120: Loss 0.1317\n",
      "Time step 18, Epoch 130: Loss 0.1190\n",
      "Time step 18, Epoch 140: Loss 0.1186\n",
      "Time step 18, Epoch 150: Loss 0.1052\n",
      "Time step 18, Epoch 160: Loss 0.1022\n",
      "Time step 18, Epoch 170: Loss 0.0916\n",
      "Time step 18, Epoch 180: Loss 0.0864\n",
      "Time step 18, Epoch 190: Loss 0.0961\n",
      "Time step 18, Epoch 200: Loss 0.0729\n",
      "Time step 18, Epoch 210: Loss 0.0691\n",
      "Time step 18, Epoch 220: Loss 0.0709\n",
      "Time step 18, Epoch 230: Loss 0.0690\n",
      "Time step 18, Epoch 240: Loss 0.0628\n",
      "Time step 18, Epoch 250: Loss 0.0609\n",
      "Time step 18, Epoch 260: Loss 0.0635\n",
      "Time step 18, Epoch 270: Loss 0.0533\n",
      "Time step 18, Epoch 280: Loss 0.0501\n",
      "Time step 18, Epoch 290: Loss 0.0513\n",
      "Time step 18, Epoch 300: Loss 0.0496\n",
      "Time step 18, Epoch 310: Loss 0.0446\n",
      "Time step 18, Epoch 320: Loss 0.0434\n",
      "Time step 18, Epoch 330: Loss 0.0400\n",
      "Time step 18, Epoch 340: Loss 0.0425\n",
      "Time step 18, Epoch 350: Loss 0.0354\n",
      "Time step 18, Epoch 360: Loss 0.0360\n",
      "Time step 18, Epoch 370: Loss 0.0353\n",
      "Time step 18, Epoch 380: Loss 0.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  37%|████████████████████████████████████████████████▊                                                                                    | 18/49 [01:19<01:59,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 18, Epoch 390: Loss 0.0440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 19, Epoch 0: Loss 4.3950\n",
      "Time step 19, Epoch 10: Loss 1.6687\n",
      "Time step 19, Epoch 20: Loss 1.0286\n",
      "Time step 19, Epoch 30: Loss 0.6294\n",
      "Time step 19, Epoch 40: Loss 0.4013\n",
      "Time step 19, Epoch 50: Loss 0.2976\n",
      "Time step 19, Epoch 60: Loss 0.2460\n",
      "Time step 19, Epoch 70: Loss 0.1967\n",
      "Time step 19, Epoch 80: Loss 0.1888\n",
      "Time step 19, Epoch 90: Loss 0.1700\n",
      "Time step 19, Epoch 100: Loss 0.1564\n",
      "Time step 19, Epoch 110: Loss 0.1509\n",
      "Time step 19, Epoch 120: Loss 0.1411\n",
      "Time step 19, Epoch 130: Loss 0.1405\n",
      "Time step 19, Epoch 140: Loss 0.1240\n",
      "Time step 19, Epoch 150: Loss 0.1314\n",
      "Time step 19, Epoch 160: Loss 0.1179\n",
      "Time step 19, Epoch 170: Loss 0.1178\n",
      "Time step 19, Epoch 180: Loss 0.1118\n",
      "Time step 19, Epoch 190: Loss 0.1086\n",
      "Time step 19, Epoch 200: Loss 0.1109\n",
      "Time step 19, Epoch 210: Loss 0.1049\n",
      "Time step 19, Epoch 220: Loss 0.0973\n",
      "Time step 19, Epoch 230: Loss 0.0930\n",
      "Time step 19, Epoch 240: Loss 0.0895\n",
      "Time step 19, Epoch 250: Loss 0.0920\n",
      "Time step 19, Epoch 260: Loss 0.0892\n",
      "Time step 19, Epoch 270: Loss 0.0812\n",
      "Time step 19, Epoch 280: Loss 0.0859\n",
      "Time step 19, Epoch 290: Loss 0.0834\n",
      "Time step 19, Epoch 300: Loss 0.0808\n",
      "Time step 19, Epoch 310: Loss 0.0729\n",
      "Time step 19, Epoch 320: Loss 0.0740\n",
      "Time step 19, Epoch 330: Loss 0.0656\n",
      "Time step 19, Epoch 340: Loss 0.0706\n",
      "Time step 19, Epoch 350: Loss 0.0672\n",
      "Time step 19, Epoch 360: Loss 0.0663\n",
      "Time step 19, Epoch 370: Loss 0.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  39%|███████████████████████████████████████████████████▌                                                                                 | 19/49 [01:23<01:57,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 19, Epoch 380: Loss 0.0709\n",
      "Time step 19, Epoch 390: Loss 0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 20, Epoch 0: Loss 4.6672\n",
      "Time step 20, Epoch 10: Loss 2.3952\n",
      "Time step 20, Epoch 20: Loss 1.4130\n",
      "Time step 20, Epoch 30: Loss 0.8275\n",
      "Time step 20, Epoch 40: Loss 0.5404\n",
      "Time step 20, Epoch 50: Loss 0.4376\n",
      "Time step 20, Epoch 60: Loss 0.3711\n",
      "Time step 20, Epoch 70: Loss 0.3321\n",
      "Time step 20, Epoch 80: Loss 0.2985\n",
      "Time step 20, Epoch 90: Loss 0.2992\n",
      "Time step 20, Epoch 100: Loss 0.2824\n",
      "Time step 20, Epoch 110: Loss 0.2713\n",
      "Time step 20, Epoch 120: Loss 0.2663\n",
      "Time step 20, Epoch 130: Loss 0.2443\n",
      "Time step 20, Epoch 140: Loss 0.2426\n",
      "Time step 20, Epoch 150: Loss 0.2273\n",
      "Time step 20, Epoch 160: Loss 0.2267\n",
      "Time step 20, Epoch 170: Loss 0.2155\n",
      "Time step 20, Epoch 180: Loss 0.2099\n",
      "Time step 20, Epoch 190: Loss 0.2076\n",
      "Time step 20, Epoch 200: Loss 0.2020\n",
      "Time step 20, Epoch 210: Loss 0.1940\n",
      "Time step 20, Epoch 220: Loss 0.2011\n",
      "Time step 20, Epoch 230: Loss 0.1835\n",
      "Time step 20, Epoch 240: Loss 0.1838\n",
      "Time step 20, Epoch 250: Loss 0.1779\n",
      "Time step 20, Epoch 260: Loss 0.1638\n",
      "Time step 20, Epoch 270: Loss 0.1722\n",
      "Time step 20, Epoch 280: Loss 0.1657\n",
      "Time step 20, Epoch 290: Loss 0.1543\n",
      "Time step 20, Epoch 300: Loss 0.1527\n",
      "Time step 20, Epoch 310: Loss 0.1552\n",
      "Time step 20, Epoch 320: Loss 0.1504\n",
      "Time step 20, Epoch 330: Loss 0.1394\n",
      "Time step 20, Epoch 340: Loss 0.1363\n",
      "Time step 20, Epoch 350: Loss 0.1342\n",
      "Time step 20, Epoch 360: Loss 0.1329\n",
      "Time step 20, Epoch 370: Loss 0.1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  41%|██████████████████████████████████████████████████████▎                                                                              | 20/49 [01:28<01:56,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 20, Epoch 380: Loss 0.1281\n",
      "Time step 20, Epoch 390: Loss 0.1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 21, Epoch 0: Loss 5.5097\n",
      "Time step 21, Epoch 10: Loss 2.2437\n",
      "Time step 21, Epoch 20: Loss 1.1670\n",
      "Time step 21, Epoch 30: Loss 0.7041\n",
      "Time step 21, Epoch 40: Loss 0.4690\n",
      "Time step 21, Epoch 50: Loss 0.3437\n",
      "Time step 21, Epoch 60: Loss 0.2820\n",
      "Time step 21, Epoch 70: Loss 0.2600\n",
      "Time step 21, Epoch 80: Loss 0.2233\n",
      "Time step 21, Epoch 90: Loss 0.2182\n",
      "Time step 21, Epoch 100: Loss 0.1939\n",
      "Time step 21, Epoch 110: Loss 0.1901\n",
      "Time step 21, Epoch 120: Loss 0.1855\n",
      "Time step 21, Epoch 130: Loss 0.1769\n",
      "Time step 21, Epoch 140: Loss 0.1694\n",
      "Time step 21, Epoch 150: Loss 0.1566\n",
      "Time step 21, Epoch 160: Loss 0.1595\n",
      "Time step 21, Epoch 170: Loss 0.1536\n",
      "Time step 21, Epoch 180: Loss 0.1459\n",
      "Time step 21, Epoch 190: Loss 0.1373\n",
      "Time step 21, Epoch 200: Loss 0.1317\n",
      "Time step 21, Epoch 210: Loss 0.1322\n",
      "Time step 21, Epoch 220: Loss 0.1206\n",
      "Time step 21, Epoch 230: Loss 0.1174\n",
      "Time step 21, Epoch 240: Loss 0.1097\n",
      "Time step 21, Epoch 250: Loss 0.1099\n",
      "Time step 21, Epoch 260: Loss 0.1095\n",
      "Time step 21, Epoch 270: Loss 0.1009\n",
      "Time step 21, Epoch 280: Loss 0.0946\n",
      "Time step 21, Epoch 290: Loss 0.1059\n",
      "Time step 21, Epoch 300: Loss 0.1011\n",
      "Time step 21, Epoch 310: Loss 0.0924\n",
      "Time step 21, Epoch 320: Loss 0.0889\n",
      "Time step 21, Epoch 330: Loss 0.0866\n",
      "Time step 21, Epoch 340: Loss 0.0778\n",
      "Time step 21, Epoch 350: Loss 0.0761\n",
      "Time step 21, Epoch 360: Loss 0.0814\n",
      "Time step 21, Epoch 370: Loss 0.0788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  43%|█████████████████████████████████████████████████████████                                                                            | 21/49 [01:32<01:51,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 21, Epoch 380: Loss 0.0768\n",
      "Time step 21, Epoch 390: Loss 0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 22, Epoch 0: Loss 8.1057\n",
      "Time step 22, Epoch 10: Loss 1.7164\n",
      "Time step 22, Epoch 20: Loss 1.0956\n",
      "Time step 22, Epoch 30: Loss 0.7302\n",
      "Time step 22, Epoch 40: Loss 0.4774\n",
      "Time step 22, Epoch 50: Loss 0.3470\n",
      "Time step 22, Epoch 60: Loss 0.2708\n",
      "Time step 22, Epoch 70: Loss 0.2301\n",
      "Time step 22, Epoch 80: Loss 0.2039\n",
      "Time step 22, Epoch 90: Loss 0.1819\n",
      "Time step 22, Epoch 100: Loss 0.1671\n",
      "Time step 22, Epoch 110: Loss 0.1618\n",
      "Time step 22, Epoch 120: Loss 0.1499\n",
      "Time step 22, Epoch 130: Loss 0.1468\n",
      "Time step 22, Epoch 140: Loss 0.1456\n",
      "Time step 22, Epoch 150: Loss 0.1393\n",
      "Time step 22, Epoch 160: Loss 0.1373\n",
      "Time step 22, Epoch 170: Loss 0.1243\n",
      "Time step 22, Epoch 180: Loss 0.1255\n",
      "Time step 22, Epoch 190: Loss 0.1212\n",
      "Time step 22, Epoch 200: Loss 0.1184\n",
      "Time step 22, Epoch 210: Loss 0.1142\n",
      "Time step 22, Epoch 220: Loss 0.1191\n",
      "Time step 22, Epoch 230: Loss 0.1109\n",
      "Time step 22, Epoch 240: Loss 0.1181\n",
      "Time step 22, Epoch 250: Loss 0.1052\n",
      "Time step 22, Epoch 260: Loss 0.1054\n",
      "Time step 22, Epoch 270: Loss 0.1054\n",
      "Time step 22, Epoch 280: Loss 0.1055\n",
      "Time step 22, Epoch 290: Loss 0.0982\n",
      "Time step 22, Epoch 300: Loss 0.0943\n",
      "Time step 22, Epoch 310: Loss 0.1020\n",
      "Time step 22, Epoch 320: Loss 0.0934\n",
      "Time step 22, Epoch 330: Loss 0.0953\n",
      "Time step 22, Epoch 340: Loss 0.0938\n",
      "Time step 22, Epoch 350: Loss 0.0921\n",
      "Time step 22, Epoch 360: Loss 0.0864\n",
      "Time step 22, Epoch 370: Loss 0.0879\n",
      "Time step 22, Epoch 380: Loss 0.0880\n",
      "Time step 22, Epoch 390: Loss 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  45%|███████████████████████████████████████████████████████████▋                                                                         | 22/49 [01:36<01:55,  4.26s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 23, Epoch 0: Loss 3.8218\n",
      "Time step 23, Epoch 10: Loss 1.0559\n",
      "Time step 23, Epoch 20: Loss 0.6187\n",
      "Time step 23, Epoch 30: Loss 0.4178\n",
      "Time step 23, Epoch 40: Loss 0.3064\n",
      "Time step 23, Epoch 50: Loss 0.2244\n",
      "Time step 23, Epoch 60: Loss 0.1843\n",
      "Time step 23, Epoch 70: Loss 0.1578\n",
      "Time step 23, Epoch 80: Loss 0.1360\n",
      "Time step 23, Epoch 90: Loss 0.1148\n",
      "Time step 23, Epoch 100: Loss 0.1044\n",
      "Time step 23, Epoch 110: Loss 0.0953\n",
      "Time step 23, Epoch 120: Loss 0.0915\n",
      "Time step 23, Epoch 130: Loss 0.0871\n",
      "Time step 23, Epoch 140: Loss 0.0829\n",
      "Time step 23, Epoch 150: Loss 0.0757\n",
      "Time step 23, Epoch 160: Loss 0.0687\n",
      "Time step 23, Epoch 170: Loss 0.0647\n",
      "Time step 23, Epoch 180: Loss 0.0642\n",
      "Time step 23, Epoch 190: Loss 0.0584\n",
      "Time step 23, Epoch 200: Loss 0.0586\n",
      "Time step 23, Epoch 210: Loss 0.0513\n",
      "Time step 23, Epoch 220: Loss 0.0491\n",
      "Time step 23, Epoch 230: Loss 0.0498\n",
      "Time step 23, Epoch 240: Loss 0.0483\n",
      "Time step 23, Epoch 250: Loss 0.0439\n",
      "Time step 23, Epoch 260: Loss 0.0436\n",
      "Time step 23, Epoch 270: Loss 0.0410\n",
      "Time step 23, Epoch 280: Loss 0.0408\n",
      "Time step 23, Epoch 290: Loss 0.0437\n",
      "Time step 23, Epoch 300: Loss 0.0364\n",
      "Time step 23, Epoch 310: Loss 0.0357\n",
      "Time step 23, Epoch 320: Loss 0.0392\n",
      "Time step 23, Epoch 330: Loss 0.0351\n",
      "Time step 23, Epoch 340: Loss 0.0333\n",
      "Time step 23, Epoch 350: Loss 0.0347\n",
      "Time step 23, Epoch 360: Loss 0.0321\n",
      "Time step 23, Epoch 370: Loss 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  47%|██████████████████████████████████████████████████████████████▍                                                                      | 23/49 [01:40<01:48,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 23, Epoch 380: Loss 0.0329\n",
      "Time step 23, Epoch 390: Loss 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 24, Epoch 0: Loss 4.8066\n",
      "Time step 24, Epoch 10: Loss 2.0487\n",
      "Time step 24, Epoch 20: Loss 1.1718\n",
      "Time step 24, Epoch 30: Loss 0.7468\n",
      "Time step 24, Epoch 40: Loss 0.5071\n",
      "Time step 24, Epoch 50: Loss 0.3790\n",
      "Time step 24, Epoch 60: Loss 0.2892\n",
      "Time step 24, Epoch 70: Loss 0.2424\n",
      "Time step 24, Epoch 80: Loss 0.2116\n",
      "Time step 24, Epoch 90: Loss 0.1980\n",
      "Time step 24, Epoch 100: Loss 0.1720\n",
      "Time step 24, Epoch 110: Loss 0.1775\n",
      "Time step 24, Epoch 120: Loss 0.1569\n",
      "Time step 24, Epoch 130: Loss 0.1459\n",
      "Time step 24, Epoch 140: Loss 0.1349\n",
      "Time step 24, Epoch 150: Loss 0.1309\n",
      "Time step 24, Epoch 160: Loss 0.1266\n",
      "Time step 24, Epoch 170: Loss 0.1187\n",
      "Time step 24, Epoch 180: Loss 0.1105\n",
      "Time step 24, Epoch 190: Loss 0.1089\n",
      "Time step 24, Epoch 200: Loss 0.0995\n",
      "Time step 24, Epoch 210: Loss 0.1026\n",
      "Time step 24, Epoch 220: Loss 0.0951\n",
      "Time step 24, Epoch 230: Loss 0.0967\n",
      "Time step 24, Epoch 240: Loss 0.0939\n",
      "Time step 24, Epoch 250: Loss 0.0826\n",
      "Time step 24, Epoch 260: Loss 0.0806\n",
      "Time step 24, Epoch 270: Loss 0.0749\n",
      "Time step 24, Epoch 280: Loss 0.0798\n",
      "Time step 24, Epoch 290: Loss 0.0675\n",
      "Time step 24, Epoch 300: Loss 0.0691\n",
      "Time step 24, Epoch 310: Loss 0.0682\n",
      "Time step 24, Epoch 320: Loss 0.0692\n",
      "Time step 24, Epoch 330: Loss 0.0638\n",
      "Time step 24, Epoch 340: Loss 0.0637\n",
      "Time step 24, Epoch 350: Loss 0.0560\n",
      "Time step 24, Epoch 360: Loss 0.0647\n",
      "Time step 24, Epoch 370: Loss 0.0563\n",
      "Time step 24, Epoch 380: Loss 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  49%|█████████████████████████████████████████████████████████████████▏                                                                   | 24/49 [01:44<01:44,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 24, Epoch 390: Loss 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 25, Epoch 0: Loss 5.5453\n",
      "Time step 25, Epoch 10: Loss 1.6405\n",
      "Time step 25, Epoch 20: Loss 0.9531\n",
      "Time step 25, Epoch 30: Loss 0.6581\n",
      "Time step 25, Epoch 40: Loss 0.4522\n",
      "Time step 25, Epoch 50: Loss 0.3476\n",
      "Time step 25, Epoch 60: Loss 0.2737\n",
      "Time step 25, Epoch 70: Loss 0.2322\n",
      "Time step 25, Epoch 80: Loss 0.2002\n",
      "Time step 25, Epoch 90: Loss 0.1729\n",
      "Time step 25, Epoch 100: Loss 0.1592\n",
      "Time step 25, Epoch 110: Loss 0.1411\n",
      "Time step 25, Epoch 120: Loss 0.1505\n",
      "Time step 25, Epoch 130: Loss 0.1382\n",
      "Time step 25, Epoch 140: Loss 0.1179\n",
      "Time step 25, Epoch 150: Loss 0.1162\n",
      "Time step 25, Epoch 160: Loss 0.1158\n",
      "Time step 25, Epoch 170: Loss 0.1025\n",
      "Time step 25, Epoch 180: Loss 0.1004\n",
      "Time step 25, Epoch 190: Loss 0.0980\n",
      "Time step 25, Epoch 200: Loss 0.0915\n",
      "Time step 25, Epoch 210: Loss 0.0850\n",
      "Time step 25, Epoch 220: Loss 0.0855\n",
      "Time step 25, Epoch 230: Loss 0.0825\n",
      "Time step 25, Epoch 240: Loss 0.0821\n",
      "Time step 25, Epoch 250: Loss 0.0820\n",
      "Time step 25, Epoch 260: Loss 0.0714\n",
      "Time step 25, Epoch 270: Loss 0.0746\n",
      "Time step 25, Epoch 280: Loss 0.0704\n",
      "Time step 25, Epoch 290: Loss 0.0630\n",
      "Time step 25, Epoch 300: Loss 0.0604\n",
      "Time step 25, Epoch 310: Loss 0.0623\n",
      "Time step 25, Epoch 320: Loss 0.0623\n",
      "Time step 25, Epoch 330: Loss 0.0566\n",
      "Time step 25, Epoch 340: Loss 0.0551\n",
      "Time step 25, Epoch 350: Loss 0.0541\n",
      "Time step 25, Epoch 360: Loss 0.0480\n",
      "Time step 25, Epoch 370: Loss 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  51%|███████████████████████████████████████████████████████████████████▊                                                                 | 25/49 [01:48<01:35,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 25, Epoch 380: Loss 0.0412\n",
      "Time step 25, Epoch 390: Loss 0.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 26, Epoch 0: Loss 3.7799\n",
      "Time step 26, Epoch 10: Loss 1.5704\n",
      "Time step 26, Epoch 20: Loss 0.8999\n",
      "Time step 26, Epoch 30: Loss 0.5515\n",
      "Time step 26, Epoch 40: Loss 0.3821\n",
      "Time step 26, Epoch 50: Loss 0.3053\n",
      "Time step 26, Epoch 60: Loss 0.2542\n",
      "Time step 26, Epoch 70: Loss 0.2269\n",
      "Time step 26, Epoch 80: Loss 0.2059\n",
      "Time step 26, Epoch 90: Loss 0.2006\n",
      "Time step 26, Epoch 100: Loss 0.1835\n",
      "Time step 26, Epoch 110: Loss 0.1726\n",
      "Time step 26, Epoch 120: Loss 0.1668\n",
      "Time step 26, Epoch 130: Loss 0.1502\n",
      "Time step 26, Epoch 140: Loss 0.1490\n",
      "Time step 26, Epoch 150: Loss 0.1461\n",
      "Time step 26, Epoch 160: Loss 0.1271\n",
      "Time step 26, Epoch 170: Loss 0.1315\n",
      "Time step 26, Epoch 180: Loss 0.1275\n",
      "Time step 26, Epoch 190: Loss 0.1176\n",
      "Time step 26, Epoch 200: Loss 0.1096\n",
      "Time step 26, Epoch 210: Loss 0.1027\n",
      "Time step 26, Epoch 220: Loss 0.1000\n",
      "Time step 26, Epoch 230: Loss 0.1053\n",
      "Time step 26, Epoch 240: Loss 0.1028\n",
      "Time step 26, Epoch 250: Loss 0.0928\n",
      "Time step 26, Epoch 260: Loss 0.0932\n",
      "Time step 26, Epoch 270: Loss 0.0929\n",
      "Time step 26, Epoch 280: Loss 0.0873\n",
      "Time step 26, Epoch 290: Loss 0.0817\n",
      "Time step 26, Epoch 300: Loss 0.0823\n",
      "Time step 26, Epoch 310: Loss 0.0763\n",
      "Time step 26, Epoch 320: Loss 0.0809\n",
      "Time step 26, Epoch 330: Loss 0.0777\n",
      "Time step 26, Epoch 340: Loss 0.0812\n",
      "Time step 26, Epoch 350: Loss 0.0725\n",
      "Time step 26, Epoch 360: Loss 0.0743\n",
      "Time step 26, Epoch 370: Loss 0.0704\n",
      "Time step 26, Epoch 380: Loss 0.0740\n",
      "Time step 26, Epoch 390: Loss 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  53%|██████████████████████████████████████████████████████████████████████▌                                                              | 26/49 [01:52<01:31,  3.97s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 27, Epoch 0: Loss 7.0946\n",
      "Time step 27, Epoch 10: Loss 1.4878\n",
      "Time step 27, Epoch 20: Loss 0.7981\n",
      "Time step 27, Epoch 30: Loss 0.4428\n",
      "Time step 27, Epoch 40: Loss 0.2897\n",
      "Time step 27, Epoch 50: Loss 0.1969\n",
      "Time step 27, Epoch 60: Loss 0.1597\n",
      "Time step 27, Epoch 70: Loss 0.1220\n",
      "Time step 27, Epoch 80: Loss 0.1077\n",
      "Time step 27, Epoch 90: Loss 0.0816\n",
      "Time step 27, Epoch 100: Loss 0.0705\n",
      "Time step 27, Epoch 110: Loss 0.0628\n",
      "Time step 27, Epoch 120: Loss 0.0695\n",
      "Time step 27, Epoch 130: Loss 0.0600\n",
      "Time step 27, Epoch 140: Loss 0.0443\n",
      "Time step 27, Epoch 150: Loss 0.0592\n",
      "Time step 27, Epoch 160: Loss 0.0460\n",
      "Time step 27, Epoch 170: Loss 0.0425\n",
      "Time step 27, Epoch 180: Loss 0.0423\n",
      "Time step 27, Epoch 190: Loss 0.0408\n",
      "Time step 27, Epoch 200: Loss 0.0436\n",
      "Time step 27, Epoch 210: Loss 0.0397\n",
      "Time step 27, Epoch 220: Loss 0.0359\n",
      "Time step 27, Epoch 230: Loss 0.0331\n",
      "Time step 27, Epoch 240: Loss 0.0270\n",
      "Time step 27, Epoch 250: Loss 0.0257\n",
      "Time step 27, Epoch 260: Loss 0.0263\n",
      "Time step 27, Epoch 270: Loss 0.0243\n",
      "Time step 27, Epoch 280: Loss 0.0254\n",
      "Time step 27, Epoch 290: Loss 0.0282\n",
      "Time step 27, Epoch 300: Loss 0.0233\n",
      "Time step 27, Epoch 310: Loss 0.0205\n",
      "Time step 27, Epoch 320: Loss 0.0257\n",
      "Time step 27, Epoch 330: Loss 0.0244\n",
      "Time step 27, Epoch 340: Loss 0.0186\n",
      "Time step 27, Epoch 350: Loss 0.0198\n",
      "Time step 27, Epoch 360: Loss 0.0290\n",
      "Time step 27, Epoch 370: Loss 0.0214\n",
      "Time step 27, Epoch 380: Loss 0.0342\n",
      "Time step 27, Epoch 390: Loss 0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  55%|█████████████████████████████████████████████████████████████████████████▎                                                           | 27/49 [01:55<01:21,  3.71s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 28, Epoch 0: Loss 5.9345\n",
      "Time step 28, Epoch 10: Loss 2.8305\n",
      "Time step 28, Epoch 20: Loss 1.4154\n",
      "Time step 28, Epoch 30: Loss 0.7520\n",
      "Time step 28, Epoch 40: Loss 0.4226\n",
      "Time step 28, Epoch 50: Loss 0.2735\n",
      "Time step 28, Epoch 60: Loss 0.1924\n",
      "Time step 28, Epoch 70: Loss 0.1509\n",
      "Time step 28, Epoch 80: Loss 0.1200\n",
      "Time step 28, Epoch 90: Loss 0.1015\n",
      "Time step 28, Epoch 100: Loss 0.0858\n",
      "Time step 28, Epoch 110: Loss 0.0856\n",
      "Time step 28, Epoch 120: Loss 0.0611\n",
      "Time step 28, Epoch 130: Loss 0.0640\n",
      "Time step 28, Epoch 140: Loss 0.0585\n",
      "Time step 28, Epoch 150: Loss 0.0558\n",
      "Time step 28, Epoch 160: Loss 0.0437\n",
      "Time step 28, Epoch 170: Loss 0.0448\n",
      "Time step 28, Epoch 180: Loss 0.0389\n",
      "Time step 28, Epoch 190: Loss 0.0379\n",
      "Time step 28, Epoch 200: Loss 0.0287\n",
      "Time step 28, Epoch 210: Loss 0.0362\n",
      "Time step 28, Epoch 220: Loss 0.0322\n",
      "Time step 28, Epoch 230: Loss 0.0296\n",
      "Time step 28, Epoch 240: Loss 0.0277\n",
      "Time step 28, Epoch 250: Loss 0.0216\n",
      "Time step 28, Epoch 260: Loss 0.0239\n",
      "Time step 28, Epoch 270: Loss 0.0240\n",
      "Time step 28, Epoch 280: Loss 0.0247\n",
      "Time step 28, Epoch 290: Loss 0.0211\n",
      "Time step 28, Epoch 300: Loss 0.0227\n",
      "Time step 28, Epoch 310: Loss 0.0248\n",
      "Time step 28, Epoch 320: Loss 0.0225\n",
      "Time step 28, Epoch 330: Loss 0.0165\n",
      "Time step 28, Epoch 340: Loss 0.0180\n",
      "Time step 28, Epoch 350: Loss 0.0162\n",
      "Time step 28, Epoch 360: Loss 0.0187\n",
      "Time step 28, Epoch 370: Loss 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  57%|████████████████████████████████████████████████████████████████████████████                                                         | 28/49 [01:58<01:13,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 28, Epoch 380: Loss 0.0178\n",
      "Time step 28, Epoch 390: Loss 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 29, Epoch 0: Loss 4.8884\n",
      "Time step 29, Epoch 10: Loss 2.1316\n",
      "Time step 29, Epoch 20: Loss 1.2322\n",
      "Time step 29, Epoch 30: Loss 0.8165\n",
      "Time step 29, Epoch 40: Loss 0.5403\n",
      "Time step 29, Epoch 50: Loss 0.3876\n",
      "Time step 29, Epoch 60: Loss 0.3059\n",
      "Time step 29, Epoch 70: Loss 0.2570\n",
      "Time step 29, Epoch 80: Loss 0.2172\n",
      "Time step 29, Epoch 90: Loss 0.2029\n",
      "Time step 29, Epoch 100: Loss 0.1813\n",
      "Time step 29, Epoch 110: Loss 0.1737\n",
      "Time step 29, Epoch 120: Loss 0.1620\n",
      "Time step 29, Epoch 130: Loss 0.1516\n",
      "Time step 29, Epoch 140: Loss 0.1415\n",
      "Time step 29, Epoch 150: Loss 0.1347\n",
      "Time step 29, Epoch 160: Loss 0.1307\n",
      "Time step 29, Epoch 170: Loss 0.1196\n",
      "Time step 29, Epoch 180: Loss 0.1190\n",
      "Time step 29, Epoch 190: Loss 0.1163\n",
      "Time step 29, Epoch 200: Loss 0.1117\n",
      "Time step 29, Epoch 210: Loss 0.1083\n",
      "Time step 29, Epoch 220: Loss 0.1055\n",
      "Time step 29, Epoch 230: Loss 0.1032\n",
      "Time step 29, Epoch 240: Loss 0.1020\n",
      "Time step 29, Epoch 250: Loss 0.0953\n",
      "Time step 29, Epoch 260: Loss 0.0951\n",
      "Time step 29, Epoch 270: Loss 0.0877\n",
      "Time step 29, Epoch 280: Loss 0.0933\n",
      "Time step 29, Epoch 290: Loss 0.0795\n",
      "Time step 29, Epoch 300: Loss 0.0860\n",
      "Time step 29, Epoch 310: Loss 0.0792\n",
      "Time step 29, Epoch 320: Loss 0.0791\n",
      "Time step 29, Epoch 330: Loss 0.0825\n",
      "Time step 29, Epoch 340: Loss 0.0774\n",
      "Time step 29, Epoch 350: Loss 0.0731\n",
      "Time step 29, Epoch 360: Loss 0.0718\n",
      "Time step 29, Epoch 370: Loss 0.0724\n",
      "Time step 29, Epoch 380: Loss 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  59%|██████████████████████████████████████████████████████████████████████████████▋                                                      | 29/49 [02:02<01:12,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 29, Epoch 390: Loss 0.0785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 30, Epoch 0: Loss 4.2709\n",
      "Time step 30, Epoch 10: Loss 2.0236\n",
      "Time step 30, Epoch 20: Loss 1.1700\n",
      "Time step 30, Epoch 30: Loss 0.7053\n",
      "Time step 30, Epoch 40: Loss 0.4193\n",
      "Time step 30, Epoch 50: Loss 0.3032\n",
      "Time step 30, Epoch 60: Loss 0.2347\n",
      "Time step 30, Epoch 70: Loss 0.2042\n",
      "Time step 30, Epoch 80: Loss 0.1721\n",
      "Time step 30, Epoch 90: Loss 0.1729\n",
      "Time step 30, Epoch 100: Loss 0.1514\n",
      "Time step 30, Epoch 110: Loss 0.1359\n",
      "Time step 30, Epoch 120: Loss 0.1370\n",
      "Time step 30, Epoch 130: Loss 0.1224\n",
      "Time step 30, Epoch 140: Loss 0.1155\n",
      "Time step 30, Epoch 150: Loss 0.1152\n",
      "Time step 30, Epoch 160: Loss 0.1004\n",
      "Time step 30, Epoch 170: Loss 0.0954\n",
      "Time step 30, Epoch 180: Loss 0.0907\n",
      "Time step 30, Epoch 190: Loss 0.0909\n",
      "Time step 30, Epoch 200: Loss 0.0795\n",
      "Time step 30, Epoch 210: Loss 0.0787\n",
      "Time step 30, Epoch 220: Loss 0.0805\n",
      "Time step 30, Epoch 230: Loss 0.0749\n",
      "Time step 30, Epoch 240: Loss 0.0692\n",
      "Time step 30, Epoch 250: Loss 0.0592\n",
      "Time step 30, Epoch 260: Loss 0.0594\n",
      "Time step 30, Epoch 270: Loss 0.0608\n",
      "Time step 30, Epoch 280: Loss 0.0615\n",
      "Time step 30, Epoch 290: Loss 0.0587\n",
      "Time step 30, Epoch 300: Loss 0.0560\n",
      "Time step 30, Epoch 310: Loss 0.0565\n",
      "Time step 30, Epoch 320: Loss 0.0497\n",
      "Time step 30, Epoch 330: Loss 0.0469\n",
      "Time step 30, Epoch 340: Loss 0.0504\n",
      "Time step 30, Epoch 350: Loss 0.0487\n",
      "Time step 30, Epoch 360: Loss 0.0450\n",
      "Time step 30, Epoch 370: Loss 0.0415\n",
      "Time step 30, Epoch 380: Loss 0.0366\n",
      "Time step 30, Epoch 390: Loss 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  61%|█████████████████████████████████████████████████████████████████████████████████▍                                                   | 30/49 [02:06<01:10,  3.70s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 31, Epoch 0: Loss 4.3612\n",
      "Time step 31, Epoch 10: Loss 1.7716\n",
      "Time step 31, Epoch 20: Loss 0.8840\n",
      "Time step 31, Epoch 30: Loss 0.5297\n",
      "Time step 31, Epoch 40: Loss 0.3485\n",
      "Time step 31, Epoch 50: Loss 0.2634\n",
      "Time step 31, Epoch 60: Loss 0.2140\n",
      "Time step 31, Epoch 70: Loss 0.1861\n",
      "Time step 31, Epoch 80: Loss 0.1649\n",
      "Time step 31, Epoch 90: Loss 0.1517\n",
      "Time step 31, Epoch 100: Loss 0.1337\n",
      "Time step 31, Epoch 110: Loss 0.1252\n",
      "Time step 31, Epoch 120: Loss 0.1267\n",
      "Time step 31, Epoch 130: Loss 0.1091\n",
      "Time step 31, Epoch 140: Loss 0.1107\n",
      "Time step 31, Epoch 150: Loss 0.1134\n",
      "Time step 31, Epoch 160: Loss 0.0977\n",
      "Time step 31, Epoch 170: Loss 0.0876\n",
      "Time step 31, Epoch 180: Loss 0.0890\n",
      "Time step 31, Epoch 190: Loss 0.0792\n",
      "Time step 31, Epoch 200: Loss 0.0850\n",
      "Time step 31, Epoch 210: Loss 0.0768\n",
      "Time step 31, Epoch 220: Loss 0.0789\n",
      "Time step 31, Epoch 230: Loss 0.0771\n",
      "Time step 31, Epoch 240: Loss 0.0795\n",
      "Time step 31, Epoch 250: Loss 0.0695\n",
      "Time step 31, Epoch 260: Loss 0.0719\n",
      "Time step 31, Epoch 270: Loss 0.0606\n",
      "Time step 31, Epoch 280: Loss 0.0680\n",
      "Time step 31, Epoch 290: Loss 0.0638\n",
      "Time step 31, Epoch 300: Loss 0.0652\n",
      "Time step 31, Epoch 310: Loss 0.0607\n",
      "Time step 31, Epoch 320: Loss 0.0527\n",
      "Time step 31, Epoch 330: Loss 0.0551\n",
      "Time step 31, Epoch 340: Loss 0.0478\n",
      "Time step 31, Epoch 350: Loss 0.0597\n",
      "Time step 31, Epoch 360: Loss 0.0560\n",
      "Time step 31, Epoch 370: Loss 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  63%|████████████████████████████████████████████████████████████████████████████████████▏                                                | 31/49 [02:09<01:05,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 31, Epoch 380: Loss 0.0521\n",
      "Time step 31, Epoch 390: Loss 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 32, Epoch 0: Loss 5.0536\n",
      "Time step 32, Epoch 10: Loss 2.3495\n",
      "Time step 32, Epoch 20: Loss 1.2128\n",
      "Time step 32, Epoch 30: Loss 0.6796\n",
      "Time step 32, Epoch 40: Loss 0.4659\n",
      "Time step 32, Epoch 50: Loss 0.3892\n",
      "Time step 32, Epoch 60: Loss 0.3249\n",
      "Time step 32, Epoch 70: Loss 0.3004\n",
      "Time step 32, Epoch 80: Loss 0.2764\n",
      "Time step 32, Epoch 90: Loss 0.2669\n",
      "Time step 32, Epoch 100: Loss 0.2607\n",
      "Time step 32, Epoch 110: Loss 0.2367\n",
      "Time step 32, Epoch 120: Loss 0.2278\n",
      "Time step 32, Epoch 130: Loss 0.2081\n",
      "Time step 32, Epoch 140: Loss 0.2060\n",
      "Time step 32, Epoch 150: Loss 0.1967\n",
      "Time step 32, Epoch 160: Loss 0.1833\n",
      "Time step 32, Epoch 170: Loss 0.1800\n",
      "Time step 32, Epoch 180: Loss 0.1806\n",
      "Time step 32, Epoch 190: Loss 0.1645\n",
      "Time step 32, Epoch 200: Loss 0.1597\n",
      "Time step 32, Epoch 210: Loss 0.1527\n",
      "Time step 32, Epoch 220: Loss 0.1534\n",
      "Time step 32, Epoch 230: Loss 0.1526\n",
      "Time step 32, Epoch 240: Loss 0.1493\n",
      "Time step 32, Epoch 250: Loss 0.1396\n",
      "Time step 32, Epoch 260: Loss 0.1355\n",
      "Time step 32, Epoch 270: Loss 0.1411\n",
      "Time step 32, Epoch 280: Loss 0.1295\n",
      "Time step 32, Epoch 290: Loss 0.1325\n",
      "Time step 32, Epoch 300: Loss 0.1245\n",
      "Time step 32, Epoch 310: Loss 0.1235\n",
      "Time step 32, Epoch 320: Loss 0.1184\n",
      "Time step 32, Epoch 330: Loss 0.1151\n",
      "Time step 32, Epoch 340: Loss 0.1121\n",
      "Time step 32, Epoch 350: Loss 0.1077\n",
      "Time step 32, Epoch 360: Loss 0.1146\n",
      "Time step 32, Epoch 370: Loss 0.1040\n",
      "Time step 32, Epoch 380: Loss 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  65%|██████████████████████████████████████████████████████████████████████████████████████▊                                              | 32/49 [02:14<01:05,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 32, Epoch 390: Loss 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 33, Epoch 0: Loss 5.1143\n",
      "Time step 33, Epoch 10: Loss 1.1036\n",
      "Time step 33, Epoch 20: Loss 0.5351\n",
      "Time step 33, Epoch 30: Loss 0.3482\n",
      "Time step 33, Epoch 40: Loss 0.2088\n",
      "Time step 33, Epoch 50: Loss 0.1426\n",
      "Time step 33, Epoch 60: Loss 0.1196\n",
      "Time step 33, Epoch 70: Loss 0.0928\n",
      "Time step 33, Epoch 80: Loss 0.0851\n",
      "Time step 33, Epoch 90: Loss 0.0737\n",
      "Time step 33, Epoch 100: Loss 0.0661\n",
      "Time step 33, Epoch 110: Loss 0.0634\n",
      "Time step 33, Epoch 120: Loss 0.0533\n",
      "Time step 33, Epoch 130: Loss 0.0587\n",
      "Time step 33, Epoch 140: Loss 0.0545\n",
      "Time step 33, Epoch 150: Loss 0.0462\n",
      "Time step 33, Epoch 160: Loss 0.0485\n",
      "Time step 33, Epoch 170: Loss 0.0469\n",
      "Time step 33, Epoch 180: Loss 0.0404\n",
      "Time step 33, Epoch 190: Loss 0.0421\n",
      "Time step 33, Epoch 200: Loss 0.0397\n",
      "Time step 33, Epoch 210: Loss 0.0401\n",
      "Time step 33, Epoch 220: Loss 0.0382\n",
      "Time step 33, Epoch 230: Loss 0.0425\n",
      "Time step 33, Epoch 240: Loss 0.0328\n",
      "Time step 33, Epoch 250: Loss 0.0309\n",
      "Time step 33, Epoch 260: Loss 0.0349\n",
      "Time step 33, Epoch 270: Loss 0.0288\n",
      "Time step 33, Epoch 280: Loss 0.0315\n",
      "Time step 33, Epoch 290: Loss 0.0368\n",
      "Time step 33, Epoch 300: Loss 0.0326\n",
      "Time step 33, Epoch 310: Loss 0.0328\n",
      "Time step 33, Epoch 320: Loss 0.0319\n",
      "Time step 33, Epoch 330: Loss 0.0276\n",
      "Time step 33, Epoch 340: Loss 0.0257\n",
      "Time step 33, Epoch 350: Loss 0.0245\n",
      "Time step 33, Epoch 360: Loss 0.0258\n",
      "Time step 33, Epoch 370: Loss 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  67%|█████████████████████████████████████████████████████████████████████████████████████████▌                                           | 33/49 [02:18<01:01,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 33, Epoch 380: Loss 0.0284\n",
      "Time step 33, Epoch 390: Loss 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 34, Epoch 0: Loss 8.0665\n",
      "Time step 34, Epoch 10: Loss 1.6603\n",
      "Time step 34, Epoch 20: Loss 0.9896\n",
      "Time step 34, Epoch 30: Loss 0.5882\n",
      "Time step 34, Epoch 40: Loss 0.3873\n",
      "Time step 34, Epoch 50: Loss 0.2798\n",
      "Time step 34, Epoch 60: Loss 0.2166\n",
      "Time step 34, Epoch 70: Loss 0.1899\n",
      "Time step 34, Epoch 80: Loss 0.1591\n",
      "Time step 34, Epoch 90: Loss 0.1366\n",
      "Time step 34, Epoch 100: Loss 0.1265\n",
      "Time step 34, Epoch 110: Loss 0.1106\n",
      "Time step 34, Epoch 120: Loss 0.1040\n",
      "Time step 34, Epoch 130: Loss 0.1143\n",
      "Time step 34, Epoch 140: Loss 0.0947\n",
      "Time step 34, Epoch 150: Loss 0.1033\n",
      "Time step 34, Epoch 160: Loss 0.0871\n",
      "Time step 34, Epoch 170: Loss 0.0874\n",
      "Time step 34, Epoch 180: Loss 0.0766\n",
      "Time step 34, Epoch 190: Loss 0.0709\n",
      "Time step 34, Epoch 200: Loss 0.0669\n",
      "Time step 34, Epoch 210: Loss 0.0693\n",
      "Time step 34, Epoch 220: Loss 0.0623\n",
      "Time step 34, Epoch 230: Loss 0.0684\n",
      "Time step 34, Epoch 240: Loss 0.0585\n",
      "Time step 34, Epoch 250: Loss 0.0625\n",
      "Time step 34, Epoch 260: Loss 0.0571\n",
      "Time step 34, Epoch 270: Loss 0.0631\n",
      "Time step 34, Epoch 280: Loss 0.0520\n",
      "Time step 34, Epoch 290: Loss 0.0522\n",
      "Time step 34, Epoch 300: Loss 0.0490\n",
      "Time step 34, Epoch 310: Loss 0.0495\n",
      "Time step 34, Epoch 320: Loss 0.0463\n",
      "Time step 34, Epoch 330: Loss 0.0442\n",
      "Time step 34, Epoch 340: Loss 0.0465\n",
      "Time step 34, Epoch 350: Loss 0.0413\n",
      "Time step 34, Epoch 360: Loss 0.0417\n",
      "Time step 34, Epoch 370: Loss 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  69%|████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 34/49 [02:21<00:57,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 34, Epoch 380: Loss 0.0354\n",
      "Time step 34, Epoch 390: Loss 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 35, Epoch 0: Loss 4.6119\n",
      "Time step 35, Epoch 10: Loss 1.8421\n",
      "Time step 35, Epoch 20: Loss 0.9296\n",
      "Time step 35, Epoch 30: Loss 0.5480\n",
      "Time step 35, Epoch 40: Loss 0.3727\n",
      "Time step 35, Epoch 50: Loss 0.2940\n",
      "Time step 35, Epoch 60: Loss 0.2659\n",
      "Time step 35, Epoch 70: Loss 0.2482\n",
      "Time step 35, Epoch 80: Loss 0.2213\n",
      "Time step 35, Epoch 90: Loss 0.2060\n",
      "Time step 35, Epoch 100: Loss 0.1939\n",
      "Time step 35, Epoch 110: Loss 0.1841\n",
      "Time step 35, Epoch 120: Loss 0.1737\n",
      "Time step 35, Epoch 130: Loss 0.1739\n",
      "Time step 35, Epoch 140: Loss 0.1678\n",
      "Time step 35, Epoch 150: Loss 0.1576\n",
      "Time step 35, Epoch 160: Loss 0.1582\n",
      "Time step 35, Epoch 170: Loss 0.1535\n",
      "Time step 35, Epoch 180: Loss 0.1489\n",
      "Time step 35, Epoch 190: Loss 0.1370\n",
      "Time step 35, Epoch 200: Loss 0.1412\n",
      "Time step 35, Epoch 210: Loss 0.1337\n",
      "Time step 35, Epoch 220: Loss 0.1290\n",
      "Time step 35, Epoch 230: Loss 0.1254\n",
      "Time step 35, Epoch 240: Loss 0.1251\n",
      "Time step 35, Epoch 250: Loss 0.1160\n",
      "Time step 35, Epoch 260: Loss 0.1133\n",
      "Time step 35, Epoch 270: Loss 0.1122\n",
      "Time step 35, Epoch 280: Loss 0.1045\n",
      "Time step 35, Epoch 290: Loss 0.1038\n",
      "Time step 35, Epoch 300: Loss 0.0988\n",
      "Time step 35, Epoch 310: Loss 0.0999\n",
      "Time step 35, Epoch 320: Loss 0.0964\n",
      "Time step 35, Epoch 330: Loss 0.0983\n",
      "Time step 35, Epoch 340: Loss 0.0943\n",
      "Time step 35, Epoch 350: Loss 0.0900\n",
      "Time step 35, Epoch 360: Loss 0.0924\n",
      "Time step 35, Epoch 370: Loss 0.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  71%|███████████████████████████████████████████████████████████████████████████████████████████████                                      | 35/49 [02:26<00:56,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 35, Epoch 380: Loss 0.0898\n",
      "Time step 35, Epoch 390: Loss 0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 36, Epoch 0: Loss 7.6699\n",
      "Time step 36, Epoch 10: Loss 2.2304\n",
      "Time step 36, Epoch 20: Loss 0.8606\n",
      "Time step 36, Epoch 30: Loss 0.4961\n",
      "Time step 36, Epoch 40: Loss 0.3180\n",
      "Time step 36, Epoch 50: Loss 0.2283\n",
      "Time step 36, Epoch 60: Loss 0.1690\n",
      "Time step 36, Epoch 70: Loss 0.1443\n",
      "Time step 36, Epoch 80: Loss 0.1320\n",
      "Time step 36, Epoch 90: Loss 0.1187\n",
      "Time step 36, Epoch 100: Loss 0.1100\n",
      "Time step 36, Epoch 110: Loss 0.0921\n",
      "Time step 36, Epoch 120: Loss 0.0885\n",
      "Time step 36, Epoch 130: Loss 0.0847\n",
      "Time step 36, Epoch 140: Loss 0.0830\n",
      "Time step 36, Epoch 150: Loss 0.0750\n",
      "Time step 36, Epoch 160: Loss 0.0689\n",
      "Time step 36, Epoch 170: Loss 0.0702\n",
      "Time step 36, Epoch 180: Loss 0.0672\n",
      "Time step 36, Epoch 190: Loss 0.0633\n",
      "Time step 36, Epoch 200: Loss 0.0597\n",
      "Time step 36, Epoch 210: Loss 0.0595\n",
      "Time step 36, Epoch 220: Loss 0.0590\n",
      "Time step 36, Epoch 230: Loss 0.0574\n",
      "Time step 36, Epoch 240: Loss 0.0549\n",
      "Time step 36, Epoch 250: Loss 0.0563\n",
      "Time step 36, Epoch 260: Loss 0.0532\n",
      "Time step 36, Epoch 270: Loss 0.0504\n",
      "Time step 36, Epoch 280: Loss 0.0510\n",
      "Time step 36, Epoch 290: Loss 0.0471\n",
      "Time step 36, Epoch 300: Loss 0.0487\n",
      "Time step 36, Epoch 310: Loss 0.0459\n",
      "Time step 36, Epoch 320: Loss 0.0466\n",
      "Time step 36, Epoch 330: Loss 0.0432\n",
      "Time step 36, Epoch 340: Loss 0.0443\n",
      "Time step 36, Epoch 350: Loss 0.0422\n",
      "Time step 36, Epoch 360: Loss 0.0382\n",
      "Time step 36, Epoch 370: Loss 0.0378\n",
      "Time step 36, Epoch 380: Loss 0.0415\n",
      "Time step 36, Epoch 390: Loss 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 36/49 [02:31<00:57,  4.44s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 37, Epoch 0: Loss 6.3998\n",
      "Time step 37, Epoch 10: Loss 1.6196\n",
      "Time step 37, Epoch 20: Loss 0.7382\n",
      "Time step 37, Epoch 30: Loss 0.4424\n",
      "Time step 37, Epoch 40: Loss 0.3070\n",
      "Time step 37, Epoch 50: Loss 0.2334\n",
      "Time step 37, Epoch 60: Loss 0.1979\n",
      "Time step 37, Epoch 70: Loss 0.1481\n",
      "Time step 37, Epoch 80: Loss 0.1488\n",
      "Time step 37, Epoch 90: Loss 0.1407\n",
      "Time step 37, Epoch 100: Loss 0.1258\n",
      "Time step 37, Epoch 110: Loss 0.1191\n",
      "Time step 37, Epoch 120: Loss 0.1056\n",
      "Time step 37, Epoch 130: Loss 0.1068\n",
      "Time step 37, Epoch 140: Loss 0.0930\n",
      "Time step 37, Epoch 150: Loss 0.0725\n",
      "Time step 37, Epoch 160: Loss 0.0769\n",
      "Time step 37, Epoch 170: Loss 0.0821\n",
      "Time step 37, Epoch 180: Loss 0.0644\n",
      "Time step 37, Epoch 190: Loss 0.0664\n",
      "Time step 37, Epoch 200: Loss 0.0693\n",
      "Time step 37, Epoch 210: Loss 0.0580\n",
      "Time step 37, Epoch 220: Loss 0.0592\n",
      "Time step 37, Epoch 230: Loss 0.0507\n",
      "Time step 37, Epoch 240: Loss 0.0575\n",
      "Time step 37, Epoch 250: Loss 0.0514\n",
      "Time step 37, Epoch 260: Loss 0.0593\n",
      "Time step 37, Epoch 270: Loss 0.0492\n",
      "Time step 37, Epoch 280: Loss 0.0496\n",
      "Time step 37, Epoch 290: Loss 0.0455\n",
      "Time step 37, Epoch 300: Loss 0.0407\n",
      "Time step 37, Epoch 310: Loss 0.0405\n",
      "Time step 37, Epoch 320: Loss 0.0402\n",
      "Time step 37, Epoch 330: Loss 0.0368\n",
      "Time step 37, Epoch 340: Loss 0.0332\n",
      "Time step 37, Epoch 350: Loss 0.0338\n",
      "Time step 37, Epoch 360: Loss 0.0401\n",
      "Time step 37, Epoch 370: Loss 0.0313\n",
      "Time step 37, Epoch 380: Loss 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                | 37/49 [02:35<00:52,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 37, Epoch 390: Loss 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 38, Epoch 0: Loss 4.3908\n",
      "Time step 38, Epoch 10: Loss 1.4007\n",
      "Time step 38, Epoch 20: Loss 0.6274\n",
      "Time step 38, Epoch 30: Loss 0.3518\n",
      "Time step 38, Epoch 40: Loss 0.2756\n",
      "Time step 38, Epoch 50: Loss 0.2229\n",
      "Time step 38, Epoch 60: Loss 0.1919\n",
      "Time step 38, Epoch 70: Loss 0.1917\n",
      "Time step 38, Epoch 80: Loss 0.1646\n",
      "Time step 38, Epoch 90: Loss 0.1631\n",
      "Time step 38, Epoch 100: Loss 0.1698\n",
      "Time step 38, Epoch 110: Loss 0.1616\n",
      "Time step 38, Epoch 120: Loss 0.1478\n",
      "Time step 38, Epoch 130: Loss 0.1294\n",
      "Time step 38, Epoch 140: Loss 0.1335\n",
      "Time step 38, Epoch 150: Loss 0.1302\n",
      "Time step 38, Epoch 160: Loss 0.1286\n",
      "Time step 38, Epoch 170: Loss 0.1188\n",
      "Time step 38, Epoch 180: Loss 0.1154\n",
      "Time step 38, Epoch 190: Loss 0.1048\n",
      "Time step 38, Epoch 200: Loss 0.1051\n",
      "Time step 38, Epoch 210: Loss 0.1163\n",
      "Time step 38, Epoch 220: Loss 0.1032\n",
      "Time step 38, Epoch 230: Loss 0.0963\n",
      "Time step 38, Epoch 240: Loss 0.0914\n",
      "Time step 38, Epoch 250: Loss 0.0954\n",
      "Time step 38, Epoch 260: Loss 0.0940\n",
      "Time step 38, Epoch 270: Loss 0.0895\n",
      "Time step 38, Epoch 280: Loss 0.0776\n",
      "Time step 38, Epoch 290: Loss 0.0754\n",
      "Time step 38, Epoch 300: Loss 0.0796\n",
      "Time step 38, Epoch 310: Loss 0.0719\n",
      "Time step 38, Epoch 320: Loss 0.0692\n",
      "Time step 38, Epoch 330: Loss 0.0677\n",
      "Time step 38, Epoch 340: Loss 0.0683\n",
      "Time step 38, Epoch 350: Loss 0.0588\n",
      "Time step 38, Epoch 360: Loss 0.0637\n",
      "Time step 38, Epoch 370: Loss 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  78%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                             | 38/49 [02:39<00:45,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 38, Epoch 380: Loss 0.0630\n",
      "Time step 38, Epoch 390: Loss 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 39, Epoch 0: Loss 3.3702\n",
      "Time step 39, Epoch 10: Loss 0.9215\n",
      "Time step 39, Epoch 20: Loss 0.4676\n",
      "Time step 39, Epoch 30: Loss 0.2826\n",
      "Time step 39, Epoch 40: Loss 0.1782\n",
      "Time step 39, Epoch 50: Loss 0.1362\n",
      "Time step 39, Epoch 60: Loss 0.1232\n",
      "Time step 39, Epoch 70: Loss 0.1013\n",
      "Time step 39, Epoch 80: Loss 0.0900\n",
      "Time step 39, Epoch 90: Loss 0.0887\n",
      "Time step 39, Epoch 100: Loss 0.0724\n",
      "Time step 39, Epoch 110: Loss 0.0696\n",
      "Time step 39, Epoch 120: Loss 0.0623\n",
      "Time step 39, Epoch 130: Loss 0.0586\n",
      "Time step 39, Epoch 140: Loss 0.0517\n",
      "Time step 39, Epoch 150: Loss 0.0511\n",
      "Time step 39, Epoch 160: Loss 0.0458\n",
      "Time step 39, Epoch 170: Loss 0.0457\n",
      "Time step 39, Epoch 180: Loss 0.0422\n",
      "Time step 39, Epoch 190: Loss 0.0417\n",
      "Time step 39, Epoch 200: Loss 0.0375\n",
      "Time step 39, Epoch 210: Loss 0.0387\n",
      "Time step 39, Epoch 220: Loss 0.0430\n",
      "Time step 39, Epoch 230: Loss 0.0371\n",
      "Time step 39, Epoch 240: Loss 0.0343\n",
      "Time step 39, Epoch 250: Loss 0.0350\n",
      "Time step 39, Epoch 260: Loss 0.0290\n",
      "Time step 39, Epoch 270: Loss 0.0311\n",
      "Time step 39, Epoch 280: Loss 0.0325\n",
      "Time step 39, Epoch 290: Loss 0.0321\n",
      "Time step 39, Epoch 300: Loss 0.0305\n",
      "Time step 39, Epoch 310: Loss 0.0283\n",
      "Time step 39, Epoch 320: Loss 0.0289\n",
      "Time step 39, Epoch 330: Loss 0.0291\n",
      "Time step 39, Epoch 340: Loss 0.0245\n",
      "Time step 39, Epoch 350: Loss 0.0251\n",
      "Time step 39, Epoch 360: Loss 0.0257\n",
      "Time step 39, Epoch 370: Loss 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 39/49 [02:43<00:40,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 39, Epoch 380: Loss 0.0222\n",
      "Time step 39, Epoch 390: Loss 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 40, Epoch 0: Loss 5.3160\n",
      "Time step 40, Epoch 10: Loss 1.6591\n",
      "Time step 40, Epoch 20: Loss 0.8418\n",
      "Time step 40, Epoch 30: Loss 0.5279\n",
      "Time step 40, Epoch 40: Loss 0.3877\n",
      "Time step 40, Epoch 50: Loss 0.3187\n",
      "Time step 40, Epoch 60: Loss 0.2663\n",
      "Time step 40, Epoch 70: Loss 0.2477\n",
      "Time step 40, Epoch 80: Loss 0.2163\n",
      "Time step 40, Epoch 90: Loss 0.2035\n",
      "Time step 40, Epoch 100: Loss 0.2167\n",
      "Time step 40, Epoch 110: Loss 0.1917\n",
      "Time step 40, Epoch 120: Loss 0.1791\n",
      "Time step 40, Epoch 130: Loss 0.1751\n",
      "Time step 40, Epoch 140: Loss 0.1838\n",
      "Time step 40, Epoch 150: Loss 0.1570\n",
      "Time step 40, Epoch 160: Loss 0.1557\n",
      "Time step 40, Epoch 170: Loss 0.1339\n",
      "Time step 40, Epoch 180: Loss 0.1415\n",
      "Time step 40, Epoch 190: Loss 0.1339\n",
      "Time step 40, Epoch 200: Loss 0.1308\n",
      "Time step 40, Epoch 210: Loss 0.1229\n",
      "Time step 40, Epoch 220: Loss 0.1263\n",
      "Time step 40, Epoch 230: Loss 0.1154\n",
      "Time step 40, Epoch 240: Loss 0.0995\n",
      "Time step 40, Epoch 250: Loss 0.1085\n",
      "Time step 40, Epoch 260: Loss 0.1096\n",
      "Time step 40, Epoch 270: Loss 0.1103\n",
      "Time step 40, Epoch 280: Loss 0.0982\n",
      "Time step 40, Epoch 290: Loss 0.0924\n",
      "Time step 40, Epoch 300: Loss 0.0938\n",
      "Time step 40, Epoch 310: Loss 0.0842\n",
      "Time step 40, Epoch 320: Loss 0.0921\n",
      "Time step 40, Epoch 330: Loss 0.0814\n",
      "Time step 40, Epoch 340: Loss 0.0781\n",
      "Time step 40, Epoch 350: Loss 0.0794\n",
      "Time step 40, Epoch 360: Loss 0.0815\n",
      "Time step 40, Epoch 370: Loss 0.0754\n",
      "Time step 40, Epoch 380: Loss 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 40/49 [02:47<00:37,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 40, Epoch 390: Loss 0.0680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 41, Epoch 0: Loss 4.6591\n",
      "Time step 41, Epoch 10: Loss 1.9346\n",
      "Time step 41, Epoch 20: Loss 0.9535\n",
      "Time step 41, Epoch 30: Loss 0.4915\n",
      "Time step 41, Epoch 40: Loss 0.3172\n",
      "Time step 41, Epoch 50: Loss 0.2611\n",
      "Time step 41, Epoch 60: Loss 0.2247\n",
      "Time step 41, Epoch 70: Loss 0.1962\n",
      "Time step 41, Epoch 80: Loss 0.1834\n",
      "Time step 41, Epoch 90: Loss 0.1647\n",
      "Time step 41, Epoch 100: Loss 0.1498\n",
      "Time step 41, Epoch 110: Loss 0.1394\n",
      "Time step 41, Epoch 120: Loss 0.1380\n",
      "Time step 41, Epoch 130: Loss 0.1297\n",
      "Time step 41, Epoch 140: Loss 0.1272\n",
      "Time step 41, Epoch 150: Loss 0.1145\n",
      "Time step 41, Epoch 160: Loss 0.1214\n",
      "Time step 41, Epoch 170: Loss 0.1062\n",
      "Time step 41, Epoch 180: Loss 0.1084\n",
      "Time step 41, Epoch 190: Loss 0.1039\n",
      "Time step 41, Epoch 200: Loss 0.1032\n",
      "Time step 41, Epoch 210: Loss 0.0900\n",
      "Time step 41, Epoch 220: Loss 0.0973\n",
      "Time step 41, Epoch 230: Loss 0.0904\n",
      "Time step 41, Epoch 240: Loss 0.0929\n",
      "Time step 41, Epoch 250: Loss 0.0845\n",
      "Time step 41, Epoch 260: Loss 0.0756\n",
      "Time step 41, Epoch 270: Loss 0.0763\n",
      "Time step 41, Epoch 280: Loss 0.0723\n",
      "Time step 41, Epoch 290: Loss 0.0740\n",
      "Time step 41, Epoch 300: Loss 0.0736\n",
      "Time step 41, Epoch 310: Loss 0.0721\n",
      "Time step 41, Epoch 320: Loss 0.0705\n",
      "Time step 41, Epoch 330: Loss 0.0677\n",
      "Time step 41, Epoch 340: Loss 0.0668\n",
      "Time step 41, Epoch 350: Loss 0.0611\n",
      "Time step 41, Epoch 360: Loss 0.0649\n",
      "Time step 41, Epoch 370: Loss 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 41/49 [02:52<00:33,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 41, Epoch 380: Loss 0.0567\n",
      "Time step 41, Epoch 390: Loss 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 42, Epoch 0: Loss 3.7622\n",
      "Time step 42, Epoch 10: Loss 1.4732\n",
      "Time step 42, Epoch 20: Loss 0.6770\n",
      "Time step 42, Epoch 30: Loss 0.4228\n",
      "Time step 42, Epoch 40: Loss 0.3156\n",
      "Time step 42, Epoch 50: Loss 0.2505\n",
      "Time step 42, Epoch 60: Loss 0.2276\n",
      "Time step 42, Epoch 70: Loss 0.2081\n",
      "Time step 42, Epoch 80: Loss 0.1901\n",
      "Time step 42, Epoch 90: Loss 0.1860\n",
      "Time step 42, Epoch 100: Loss 0.1666\n",
      "Time step 42, Epoch 110: Loss 0.1618\n",
      "Time step 42, Epoch 120: Loss 0.1610\n",
      "Time step 42, Epoch 130: Loss 0.1570\n",
      "Time step 42, Epoch 140: Loss 0.1505\n",
      "Time step 42, Epoch 150: Loss 0.1431\n",
      "Time step 42, Epoch 160: Loss 0.1402\n",
      "Time step 42, Epoch 170: Loss 0.1325\n",
      "Time step 42, Epoch 180: Loss 0.1239\n",
      "Time step 42, Epoch 190: Loss 0.1217\n",
      "Time step 42, Epoch 200: Loss 0.1209\n",
      "Time step 42, Epoch 210: Loss 0.1144\n",
      "Time step 42, Epoch 220: Loss 0.1213\n",
      "Time step 42, Epoch 230: Loss 0.1155\n",
      "Time step 42, Epoch 240: Loss 0.1065\n",
      "Time step 42, Epoch 250: Loss 0.1052\n",
      "Time step 42, Epoch 260: Loss 0.1069\n",
      "Time step 42, Epoch 270: Loss 0.1010\n",
      "Time step 42, Epoch 280: Loss 0.1026\n",
      "Time step 42, Epoch 290: Loss 0.1002\n",
      "Time step 42, Epoch 300: Loss 0.0951\n",
      "Time step 42, Epoch 310: Loss 0.0964\n",
      "Time step 42, Epoch 320: Loss 0.0905\n",
      "Time step 42, Epoch 330: Loss 0.0886\n",
      "Time step 42, Epoch 340: Loss 0.0909\n",
      "Time step 42, Epoch 350: Loss 0.0912\n",
      "Time step 42, Epoch 360: Loss 0.0816\n",
      "Time step 42, Epoch 370: Loss 0.0865\n",
      "Time step 42, Epoch 380: Loss 0.0811\n",
      "Time step 42, Epoch 390: Loss 0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 42/49 [02:57<00:32,  4.57s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 43, Epoch 0: Loss 5.4621\n",
      "Time step 43, Epoch 10: Loss 1.7886\n",
      "Time step 43, Epoch 20: Loss 0.5164\n",
      "Time step 43, Epoch 30: Loss 0.2407\n",
      "Time step 43, Epoch 40: Loss 0.1473\n",
      "Time step 43, Epoch 50: Loss 0.1098\n",
      "Time step 43, Epoch 60: Loss 0.0926\n",
      "Time step 43, Epoch 70: Loss 0.0832\n",
      "Time step 43, Epoch 80: Loss 0.0759\n",
      "Time step 43, Epoch 90: Loss 0.0648\n",
      "Time step 43, Epoch 100: Loss 0.0598\n",
      "Time step 43, Epoch 110: Loss 0.0568\n",
      "Time step 43, Epoch 120: Loss 0.0499\n",
      "Time step 43, Epoch 130: Loss 0.0524\n",
      "Time step 43, Epoch 140: Loss 0.0512\n",
      "Time step 43, Epoch 150: Loss 0.0431\n",
      "Time step 43, Epoch 160: Loss 0.0449\n",
      "Time step 43, Epoch 170: Loss 0.0399\n",
      "Time step 43, Epoch 180: Loss 0.0365\n",
      "Time step 43, Epoch 190: Loss 0.0320\n",
      "Time step 43, Epoch 200: Loss 0.0333\n",
      "Time step 43, Epoch 210: Loss 0.0318\n",
      "Time step 43, Epoch 220: Loss 0.0329\n",
      "Time step 43, Epoch 230: Loss 0.0260\n",
      "Time step 43, Epoch 240: Loss 0.0276\n",
      "Time step 43, Epoch 250: Loss 0.0254\n",
      "Time step 43, Epoch 260: Loss 0.0217\n",
      "Time step 43, Epoch 270: Loss 0.0224\n",
      "Time step 43, Epoch 280: Loss 0.0215\n",
      "Time step 43, Epoch 290: Loss 0.0209\n",
      "Time step 43, Epoch 300: Loss 0.0186\n",
      "Time step 43, Epoch 310: Loss 0.0192\n",
      "Time step 43, Epoch 320: Loss 0.0149\n",
      "Time step 43, Epoch 330: Loss 0.0160\n",
      "Time step 43, Epoch 340: Loss 0.0138\n",
      "Time step 43, Epoch 350: Loss 0.0146\n",
      "Time step 43, Epoch 360: Loss 0.0167\n",
      "Time step 43, Epoch 370: Loss 0.0167\n",
      "Time step 43, Epoch 380: Loss 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 43/49 [03:01<00:26,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 43, Epoch 390: Loss 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 44, Epoch 0: Loss 4.5273\n",
      "Time step 44, Epoch 10: Loss 2.0087\n",
      "Time step 44, Epoch 20: Loss 0.7817\n",
      "Time step 44, Epoch 30: Loss 0.3042\n",
      "Time step 44, Epoch 40: Loss 0.1745\n",
      "Time step 44, Epoch 50: Loss 0.1332\n",
      "Time step 44, Epoch 60: Loss 0.1143\n",
      "Time step 44, Epoch 70: Loss 0.0982\n",
      "Time step 44, Epoch 80: Loss 0.0877\n",
      "Time step 44, Epoch 90: Loss 0.0834\n",
      "Time step 44, Epoch 100: Loss 0.0796\n",
      "Time step 44, Epoch 110: Loss 0.0762\n",
      "Time step 44, Epoch 120: Loss 0.0781\n",
      "Time step 44, Epoch 130: Loss 0.0684\n",
      "Time step 44, Epoch 140: Loss 0.0629\n",
      "Time step 44, Epoch 150: Loss 0.0611\n",
      "Time step 44, Epoch 160: Loss 0.0598\n",
      "Time step 44, Epoch 170: Loss 0.0576\n",
      "Time step 44, Epoch 180: Loss 0.0535\n",
      "Time step 44, Epoch 190: Loss 0.0510\n",
      "Time step 44, Epoch 200: Loss 0.0534\n",
      "Time step 44, Epoch 210: Loss 0.0451\n",
      "Time step 44, Epoch 220: Loss 0.0455\n",
      "Time step 44, Epoch 230: Loss 0.0456\n",
      "Time step 44, Epoch 240: Loss 0.0388\n",
      "Time step 44, Epoch 250: Loss 0.0387\n",
      "Time step 44, Epoch 260: Loss 0.0339\n",
      "Time step 44, Epoch 270: Loss 0.0372\n",
      "Time step 44, Epoch 280: Loss 0.0348\n",
      "Time step 44, Epoch 290: Loss 0.0338\n",
      "Time step 44, Epoch 300: Loss 0.0292\n",
      "Time step 44, Epoch 310: Loss 0.0312\n",
      "Time step 44, Epoch 320: Loss 0.0286\n",
      "Time step 44, Epoch 330: Loss 0.0281\n",
      "Time step 44, Epoch 340: Loss 0.0283\n",
      "Time step 44, Epoch 350: Loss 0.0274\n",
      "Time step 44, Epoch 360: Loss 0.0240\n",
      "Time step 44, Epoch 370: Loss 0.0218\n",
      "Time step 44, Epoch 380: Loss 0.0227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 44/49 [03:06<00:21,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 44, Epoch 390: Loss 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 45, Epoch 0: Loss 7.1551\n",
      "Time step 45, Epoch 10: Loss 2.5550\n",
      "Time step 45, Epoch 20: Loss 1.0617\n",
      "Time step 45, Epoch 30: Loss 0.5171\n",
      "Time step 45, Epoch 40: Loss 0.2847\n",
      "Time step 45, Epoch 50: Loss 0.1735\n",
      "Time step 45, Epoch 60: Loss 0.1157\n",
      "Time step 45, Epoch 70: Loss 0.0860\n",
      "Time step 45, Epoch 80: Loss 0.0658\n",
      "Time step 45, Epoch 90: Loss 0.0555\n",
      "Time step 45, Epoch 100: Loss 0.0448\n",
      "Time step 45, Epoch 110: Loss 0.0358\n",
      "Time step 45, Epoch 120: Loss 0.0323\n",
      "Time step 45, Epoch 130: Loss 0.0301\n",
      "Time step 45, Epoch 140: Loss 0.0260\n",
      "Time step 45, Epoch 150: Loss 0.0204\n",
      "Time step 45, Epoch 160: Loss 0.0198\n",
      "Time step 45, Epoch 170: Loss 0.0173\n",
      "Time step 45, Epoch 180: Loss 0.0186\n",
      "Time step 45, Epoch 190: Loss 0.0151\n",
      "Time step 45, Epoch 200: Loss 0.0141\n",
      "Time step 45, Epoch 210: Loss 0.0145\n",
      "Time step 45, Epoch 220: Loss 0.0119\n",
      "Time step 45, Epoch 230: Loss 0.0100\n",
      "Time step 45, Epoch 240: Loss 0.0110\n",
      "Time step 45, Epoch 250: Loss 0.0103\n",
      "Time step 45, Epoch 260: Loss 0.0098\n",
      "Time step 45, Epoch 270: Loss 0.0131\n",
      "Time step 45, Epoch 280: Loss 0.0100\n",
      "Time step 45, Epoch 290: Loss 0.0086\n",
      "Time step 45, Epoch 300: Loss 0.0078\n",
      "Time step 45, Epoch 310: Loss 0.0069\n",
      "Time step 45, Epoch 320: Loss 0.0080\n",
      "Time step 45, Epoch 330: Loss 0.0072\n",
      "Time step 45, Epoch 340: Loss 0.0061\n",
      "Time step 45, Epoch 350: Loss 0.0046\n",
      "Time step 45, Epoch 360: Loss 0.0052\n",
      "Time step 45, Epoch 370: Loss 0.0057\n",
      "Time step 45, Epoch 380: Loss 0.0043\n",
      "Time step 45, Epoch 390: Loss 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 45/49 [03:10<00:17,  4.45s/it]/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 46, Epoch 0: Loss 5.6014\n",
      "Time step 46, Epoch 10: Loss 1.6252\n",
      "Time step 46, Epoch 20: Loss 0.3690\n",
      "Time step 46, Epoch 30: Loss 0.1497\n",
      "Time step 46, Epoch 40: Loss 0.0777\n",
      "Time step 46, Epoch 50: Loss 0.0448\n",
      "Time step 46, Epoch 60: Loss 0.0308\n",
      "Time step 46, Epoch 70: Loss 0.0226\n",
      "Time step 46, Epoch 80: Loss 0.0148\n",
      "Time step 46, Epoch 90: Loss 0.0157\n",
      "Time step 46, Epoch 100: Loss 0.0115\n",
      "Time step 46, Epoch 110: Loss 0.0118\n",
      "Time step 46, Epoch 120: Loss 0.0104\n",
      "Time step 46, Epoch 130: Loss 0.0080\n",
      "Time step 46, Epoch 140: Loss 0.0070\n",
      "Time step 46, Epoch 150: Loss 0.0079\n",
      "Time step 46, Epoch 160: Loss 0.0052\n",
      "Time step 46, Epoch 170: Loss 0.0077\n",
      "Time step 46, Epoch 180: Loss 0.0062\n",
      "Time step 46, Epoch 190: Loss 0.0048\n",
      "Time step 46, Epoch 200: Loss 0.0034\n",
      "Time step 46, Epoch 210: Loss 0.0032\n",
      "Time step 46, Epoch 220: Loss 0.0052\n",
      "Time step 46, Epoch 230: Loss 0.0067\n",
      "Time step 46, Epoch 240: Loss 0.0042\n",
      "Time step 46, Epoch 250: Loss 0.0029\n",
      "Time step 46, Epoch 260: Loss 0.0031\n",
      "Time step 46, Epoch 270: Loss 0.0026\n",
      "Time step 46, Epoch 280: Loss 0.0025\n",
      "Time step 46, Epoch 290: Loss 0.0030\n",
      "Time step 46, Epoch 300: Loss 0.0027\n",
      "Time step 46, Epoch 310: Loss 0.0024\n",
      "Time step 46, Epoch 320: Loss 0.0022\n",
      "Time step 46, Epoch 330: Loss 0.0020\n",
      "Time step 46, Epoch 340: Loss 0.0021\n",
      "Time step 46, Epoch 350: Loss 0.0020\n",
      "Time step 46, Epoch 360: Loss 0.0025\n",
      "Time step 46, Epoch 370: Loss 0.0015\n",
      "Time step 46, Epoch 380: Loss 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 46/49 [03:14<00:12,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 46, Epoch 390: Loss 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 47, Epoch 0: Loss 4.7544\n",
      "Time step 47, Epoch 10: Loss 1.2379\n",
      "Time step 47, Epoch 20: Loss 0.5064\n",
      "Time step 47, Epoch 30: Loss 0.2823\n",
      "Time step 47, Epoch 40: Loss 0.1944\n",
      "Time step 47, Epoch 50: Loss 0.1445\n",
      "Time step 47, Epoch 60: Loss 0.1089\n",
      "Time step 47, Epoch 70: Loss 0.0941\n",
      "Time step 47, Epoch 80: Loss 0.0842\n",
      "Time step 47, Epoch 90: Loss 0.0684\n",
      "Time step 47, Epoch 100: Loss 0.0622\n",
      "Time step 47, Epoch 110: Loss 0.0624\n",
      "Time step 47, Epoch 120: Loss 0.0550\n",
      "Time step 47, Epoch 130: Loss 0.0493\n",
      "Time step 47, Epoch 140: Loss 0.0470\n",
      "Time step 47, Epoch 150: Loss 0.0383\n",
      "Time step 47, Epoch 160: Loss 0.0332\n",
      "Time step 47, Epoch 170: Loss 0.0349\n",
      "Time step 47, Epoch 180: Loss 0.0357\n",
      "Time step 47, Epoch 190: Loss 0.0303\n",
      "Time step 47, Epoch 200: Loss 0.0244\n",
      "Time step 47, Epoch 210: Loss 0.0239\n",
      "Time step 47, Epoch 220: Loss 0.0265\n",
      "Time step 47, Epoch 230: Loss 0.0215\n",
      "Time step 47, Epoch 240: Loss 0.0202\n",
      "Time step 47, Epoch 250: Loss 0.0164\n",
      "Time step 47, Epoch 260: Loss 0.0183\n",
      "Time step 47, Epoch 270: Loss 0.0167\n",
      "Time step 47, Epoch 280: Loss 0.0152\n",
      "Time step 47, Epoch 290: Loss 0.0162\n",
      "Time step 47, Epoch 300: Loss 0.0139\n",
      "Time step 47, Epoch 310: Loss 0.0168\n",
      "Time step 47, Epoch 320: Loss 0.0130\n",
      "Time step 47, Epoch 330: Loss 0.0141\n",
      "Time step 47, Epoch 340: Loss 0.0148\n",
      "Time step 47, Epoch 350: Loss 0.0137\n",
      "Time step 47, Epoch 360: Loss 0.0126\n",
      "Time step 47, Epoch 370: Loss 0.0161\n",
      "Time step 47, Epoch 380: Loss 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌     | 47/49 [03:18<00:08,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 47, Epoch 390: Loss 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 48, Epoch 0: Loss 11.8723\n",
      "Time step 48, Epoch 10: Loss 2.4215\n",
      "Time step 48, Epoch 20: Loss 0.6063\n",
      "Time step 48, Epoch 30: Loss 0.3806\n",
      "Time step 48, Epoch 40: Loss 0.2505\n",
      "Time step 48, Epoch 50: Loss 0.1774\n",
      "Time step 48, Epoch 60: Loss 0.1592\n",
      "Time step 48, Epoch 70: Loss 0.1226\n",
      "Time step 48, Epoch 80: Loss 0.1042\n",
      "Time step 48, Epoch 90: Loss 0.0984\n",
      "Time step 48, Epoch 100: Loss 0.0609\n",
      "Time step 48, Epoch 110: Loss 0.0796\n",
      "Time step 48, Epoch 120: Loss 0.0614\n",
      "Time step 48, Epoch 130: Loss 0.0601\n",
      "Time step 48, Epoch 140: Loss 0.0559\n",
      "Time step 48, Epoch 150: Loss 0.0473\n",
      "Time step 48, Epoch 160: Loss 0.0486\n",
      "Time step 48, Epoch 170: Loss 0.0385\n",
      "Time step 48, Epoch 180: Loss 0.0346\n",
      "Time step 48, Epoch 190: Loss 0.0411\n",
      "Time step 48, Epoch 200: Loss 0.0364\n",
      "Time step 48, Epoch 210: Loss 0.0335\n",
      "Time step 48, Epoch 220: Loss 0.0270\n",
      "Time step 48, Epoch 230: Loss 0.0222\n",
      "Time step 48, Epoch 240: Loss 0.0268\n",
      "Time step 48, Epoch 250: Loss 0.0201\n",
      "Time step 48, Epoch 260: Loss 0.0231\n",
      "Time step 48, Epoch 270: Loss 0.0180\n",
      "Time step 48, Epoch 280: Loss 0.0182\n",
      "Time step 48, Epoch 290: Loss 0.0178\n",
      "Time step 48, Epoch 300: Loss 0.0182\n",
      "Time step 48, Epoch 310: Loss 0.0167\n",
      "Time step 48, Epoch 320: Loss 0.0148\n",
      "Time step 48, Epoch 330: Loss 0.0119\n",
      "Time step 48, Epoch 340: Loss 0.0189\n",
      "Time step 48, Epoch 350: Loss 0.0117\n",
      "Time step 48, Epoch 360: Loss 0.0111\n",
      "Time step 48, Epoch 370: Loss 0.0132\n",
      "Time step 48, Epoch 380: Loss 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 48/49 [03:22<00:04,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 48, Epoch 390: Loss 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/AML/src/features/network_features.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_mask = torch.tensor(train_mask, dtype=torch.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 49, Epoch 0: Loss 4.0436\n",
      "Time step 49, Epoch 10: Loss 1.1105\n",
      "Time step 49, Epoch 20: Loss 0.4244\n",
      "Time step 49, Epoch 30: Loss 0.2112\n",
      "Time step 49, Epoch 40: Loss 0.1525\n",
      "Time step 49, Epoch 50: Loss 0.1291\n",
      "Time step 49, Epoch 60: Loss 0.0960\n",
      "Time step 49, Epoch 70: Loss 0.0824\n",
      "Time step 49, Epoch 80: Loss 0.0705\n",
      "Time step 49, Epoch 90: Loss 0.0673\n",
      "Time step 49, Epoch 100: Loss 0.0692\n",
      "Time step 49, Epoch 110: Loss 0.0558\n",
      "Time step 49, Epoch 120: Loss 0.0482\n",
      "Time step 49, Epoch 130: Loss 0.0442\n",
      "Time step 49, Epoch 140: Loss 0.0409\n",
      "Time step 49, Epoch 150: Loss 0.0340\n",
      "Time step 49, Epoch 160: Loss 0.0373\n",
      "Time step 49, Epoch 170: Loss 0.0392\n",
      "Time step 49, Epoch 180: Loss 0.0356\n",
      "Time step 49, Epoch 190: Loss 0.0292\n",
      "Time step 49, Epoch 200: Loss 0.0252\n",
      "Time step 49, Epoch 210: Loss 0.0272\n",
      "Time step 49, Epoch 220: Loss 0.0288\n",
      "Time step 49, Epoch 230: Loss 0.0241\n",
      "Time step 49, Epoch 240: Loss 0.0209\n",
      "Time step 49, Epoch 250: Loss 0.0172\n",
      "Time step 49, Epoch 260: Loss 0.0188\n",
      "Time step 49, Epoch 270: Loss 0.0145\n",
      "Time step 49, Epoch 280: Loss 0.0159\n",
      "Time step 49, Epoch 290: Loss 0.0168\n",
      "Time step 49, Epoch 300: Loss 0.0155\n",
      "Time step 49, Epoch 310: Loss 0.0124\n",
      "Time step 49, Epoch 320: Loss 0.0117\n",
      "Time step 49, Epoch 330: Loss 0.0123\n",
      "Time step 49, Epoch 340: Loss 0.0139\n",
      "Time step 49, Epoch 350: Loss 0.0110\n",
      "Time step 49, Epoch 360: Loss 0.0109\n",
      "Time step 49, Epoch 370: Loss 0.0105\n",
      "Time step 49, Epoch 380: Loss 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GCN Embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [03:26<00:00,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 49, Epoch 390: Loss 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "feature_cols = nodes_df.drop(columns=['txId', 'time_step', 'class_label']).columns.to_list()\n",
    "# 5. Train GCN and get embeddings\n",
    "gcn_embeddings = train_gcn_get_embeddings(nodes_df, time_step_graphs, feature_cols, device=mps_device, epochs =400)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b3ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "379ee7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging features...\n"
     ]
    }
   ],
   "source": [
    "# 5. Merge all features\n",
    "print(\"Merging features...\")\n",
    "final_df = nodes_df.merge(gw_features, on='txId', how='left')\n",
    "final_df = final_df.merge(gcn_embeddings, on='txId', how='left')\n",
    "final_df.to_parquet('data/processed/df_model.parquet', partition_cols='time_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # 4. Compute GuiltyWalker features\n",
    "    print(\"Computing GuiltyWalker features...\")\n",
    "    gw_features = guilty_walker_features(G, labels)\n",
    "    \n",
    "    # 5. Train GCN and get embeddings\n",
    "    print(\"Training GCN and getting embeddings...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    gcn_embeddings = train_gcn_get_embeddings(G, df, feature_cols, device=device)\n",
    "    \n",
    "    # 6. Merge all features\n",
    "    print(\"Merging features...\")\n",
    "    final_df = df.merge(gw_features, on='txId', how='left')\n",
    "    final_df = final_df.merge(gcn_embeddings, on='txId', how='left')\n",
    "    \n",
    "    # 7. Train classifier (time-based split as in the paper)\n",
    "    print(\"Training classifier...\")\n",
    "    # Split by timestep (34 is the cutoff mentioned in the paper)\n",
    "    train_mask = final_df['time_step'] <= 34\n",
    "    test_mask = final_df['time_step'] > 34\n",
    "    \n",
    "    # Prepare features\n",
    "    X_cols = feature_cols + [c for c in final_df.columns if c.startswith('gw_') or c.startswith('gcn_')]\n",
    "    X = final_df[X_cols].values\n",
    "    # Class '2' is illicit\n",
    "    y = (final_df['class_label'] == '2').astype(int).values\n",
    "    \n",
    "    X_train = X[train_mask]\n",
    "    y_train = y[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_test = y[test_mask]\n",
    "    \n",
    "    # Train Random Forest\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
